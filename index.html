<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 3.7.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>CHAO LI&#39;s Blog</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="CHAO LI&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="CHAO LI&#39;s Blog">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CHAO LI&#39;s Blog">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?4ca08f1c48fe3bf3d0e2bfb54473d985";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    <script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/hadoop_logo.jpg" alt="CHAO LI&#39;s Blog" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item is-active"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main">
    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-01-06T17:42:13.000Z">2020-01-07</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 分钟 读完 (大约 917 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/01/07/MR任务在Hadoop子系统中状态流转/">MR任务在Hadoop子系统中状态流转</a>
            
        </h1>
        <div class="content">
            <p>深入做hadoop相关的工作也有一段时间了，期间零零散散看了不少源码，但很多都是看完就忘了，很难形成结构化的记忆。于是决定通过流程图的方式来刻画一个MR任务在Hadoop子系统中的状态机流转过程。<br><a href="https://zhuanlan.zhihu.com/p/101352679" target="_blank" rel="noopener">知乎链接</a></p>
<h2 id="MR任务提交过程"><a href="#MR任务提交过程" class="headerlink" title="MR任务提交过程"></a>MR任务提交过程</h2><p><img src="https://pic1.zhimg.com/80/v2-73ff12c7a51dc7962821e06d67c9be1c_hd.png" alt="img"></p>
<p>一个MR任务在hadoop 客户端通过rpc 方式提交到yarn上；大致过程如上图</p>
<ul>
<li>JobSubmitter<ul>
<li>封装了向yarn(ClientRMService)提交的过程</li>
<li>与hdfs交互计算任务输入数据的分片大小，以及将jar包加入DistributedCache中</li>
</ul>
</li>
<li>ClientServiceDelegate<ul>
<li>设计的目的是统一封装monitorJob过程获取任务执行状态，counters等信息的rpc client代理；其背后通过Java反射的方式，在任务的不同阶段会分别请求RM, AM, 或MR History Server（以下简称MHS）服务</li>
<li>因各种情况会有部分线上任务流量降级穿透到MHS服务，而MHS服务自身实现有较大瓶颈，我们其进行了leveldb方案的改造，整体查询性能提升<strong>20倍</strong></li>
</ul>
</li>
</ul>
<h2 id="分片计算过程"><a href="#分片计算过程" class="headerlink" title="分片计算过程"></a>分片计算过程</h2><p>下面看一下getSplits过程，我们默认用的是CombineFileInputFormat实现，先上图</p>
<p><img src="https://pic4.zhimg.com/80/v2-8add590ce801446aef9d08c031a8c3ff_hd.png" alt="img"></p>
<p>我们知道，MR计算框架强调的是数据本地性。在图中有三个结构nodeToBlocks，rackToBlocks，blockToNodes；其中nodeToBlocks代表的是local级别，优先选择此集合中的分片，当剩下的blocks不足minSizeNode阈值时会通过blockToNodes数据结构，进行次优的分片划分的过程，以此类推。</p>
<h2 id="ApplicationMaster启动过程"><a href="#ApplicationMaster启动过程" class="headerlink" title="ApplicationMaster启动过程"></a>ApplicationMaster启动过程</h2><p>当一个任务提交到RM后，需要等待RM分配资源启动AM之后才开始后续自己的资源&amp;任务处理过程，先上图（<strong>以下板块省去了内部自实现的调度算法</strong>）</p>
<p><img src="https://pic1.zhimg.com/80/v2-616195ee1bab87905cb4e3c31182142c_hd.png" alt="img"></p>
<p>此时涉及到RMApp, RMAppAttempt，RMNode，以及RMContainer等状态机的轮转</p>
<p><img src="https://pic4.zhimg.com/80/v2-3f2f539ad5ebb736d7a85d4b606a9683_hd.png" alt="img"></p>
<h2 id="MR任务状态机流转"><a href="#MR任务状态机流转" class="headerlink" title="MR任务状态机流转"></a>MR任务状态机流转</h2><p>当Yarn RM通过ContainerManagerProtocol协议将AM Container启动之后，AM便开始了Map/Reduce（一般map执行完之后）任务调度过程</p>
<p><img src="http://jacobs.wanhb.cn/images/mr_job_trans.jpg" alt="事务处理相关类的层次结构"></p>
<p>运行期间涉及到的状态机有Job, Task, 以及TaskAttempt，当然还有AM register/unregister过程Yarn RM系统对应的状态机转换；大致描述一下流程：</p>
<ul>
<li>MR AM启动，通过Job状态机初始化<ul>
<li>初始化CommitterEventHandler，用于最后job完成时通过commit过程将temp目录的数据转移到final 目录中</li>
<li>初始化Map/Reduce Task以及对应的TaskAttempt（Task具体的某次尝试），通过RMContainerAllocator先对map task进行调度，后进行reduce task调度</li>
</ul>
</li>
<li>通过ApplicationMasterService向RM注册自己，代表某个RMAppAttempt对应的AM Container已启动，可以定期向RM发送allocate心跳了</li>
<li>在RMContainerAllocator中通过allocate心跳向RM请求资源，得到response之后将分得的container再按优先级assign给对应的task</li>
<li>在TaskAttempt得到container之后通过ContainerLanucher向NodeManager请求启动Container</li>
<li>任务运行完成做对应的commit，clean操作之后，通过ApplicatioinMasterService告知RM任务完成，此时RMApp/Attempt做任务完成的状态转换</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-11-04T17:47:46.000Z">2019-11-05</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    19 分钟 读完 (大约 2854 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/11/05/Yarn-Federation源码串读/">Yarn Federation源码串读</a>
            
        </h1>
        <div class="content">
            <p><a href="https://zhuanlan.zhihu.com/p/79378807" target="_blank" rel="noopener">知乎链接</a></p>
<h2 id="Federation架构总览"><a href="#Federation架构总览" class="headerlink" title="Federation架构总览"></a>Federation架构总览</h2><ul>
<li>Federation: 主要有四个模块，Router ，StateStore，AMRMProxy, Global Policy Generator；从架构上来看，有点类似于后端的微服务架构中<strong>服务注册发现</strong>模块</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-7ee20bc86d8be49d25b5ca3897d3278f_b.png" alt="img"></p>
<h2 id="Router模块"><a href="#Router模块" class="headerlink" title="Router模块"></a>Router模块</h2><ul>
<li>类似于微服务的网关模块；通过state store获取具体的集群配置策略，将client端submit请求转发到对应的subCluster中</li>
<li>代码结构</li>
<li>hadoop-yarn-server-router：router组件核心实现，分为对接admin用户的协议和client用户协议，以及web server三个子模块实现  </li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-b6ee24339266083c97b6642c4f3a081e_b.png" alt="img"></p>
<ul>
<li>hadoop-yarn-server-common-federation-router：包含了Router的各种Policy，具体控制router给子集群分配app的策略</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-e7402699fce4808743375957f68a8b11_b.png" alt="img"></p>
<h3 id="Router-clientrm"><a href="#Router-clientrm" class="headerlink" title="Router- clientrm"></a><strong>Router- clientrm</strong></h3><ul>
<li>负责接收客户端命令请求，并根据对应router具体配置的policy将客户端请求转发到HomeSubcluster上</li>
<li>在每一个router服务上随着启动，用来监听客户端作业提交，实现了Client与RM沟通的RPC协议接口(ApplicationClientProtocol)；作为client的proxy，执行一系列的chain interceptor），通常FederationClientInterceptor需作为最后一个拦截器</li>
<li>当然RouterClientRMService某种程度上针对的是Server测，取代原来RM侧<strong>RMClientService</strong>；在客户端具体的调用还是在<strong>YarnClientImpl</strong>；之间通过RPC通信</li>
<li>初始化： 获取配置文件中配置的拦截器，默认是DefaultClientRequestInterceptor  </li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-74b97de7e4a90be9f4f7f5e703dcbd56_b.png" alt="img"></p>
<ul>
<li>DefaultClientRequestInterceptor只是做了简单的请求透明转发；没涉及到多子集群的处理</li>
<li>FederationClientInterceptor：面向client，隐藏了多个sub cluster RM；但是目前只实现了四个接口：<strong>getNewApplication, submitApplication, forceKillApplication and getApplicationReport</strong></li>
<li><strong>FederationClientInterceptor</strong></li>
<li>clientRMProxies: 子集群id与对应的通信client的key value集合</li>
<li>federationFacade: 对应的state store具体实现</li>
<li>policyFacade: 路由策略的工厂  </li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-d6bbfd466b88388bdb9777d17d159210_b.png" alt="img"></p>
<ul>
<li>一个任务的提交需经过<strong>FederationClientInterceptor.getNewApplication</strong>和<strong>submitApplication</strong>接口，前者获得新的<strong>applicationId</strong>, 后者通过获得的<strong>applicationId</strong>将任务提交到具体的sub Cluster RM；这一个阶段没有经过与state store的写操作</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-6824ab1d9c5489ea0264ef5b79f9f075_b.png" alt="img"></p>
<ul>
<li>getNewApplication实现只是<strong>随机</strong>的选择一个active sub cluster来获取一个新的<strong>applicationId</strong>；而subClustersActive是通过具体实现的<strong>state store</strong>来获取，此处有过滤active的字段</li>
<li>submitApplication，方法注释有讨论各种failover的处理情况；</li>
<li>RM没挂的情况：如果state store 更新成功了，则多次提交任务都是幂等的</li>
<li>RM挂了：则router time out之后重试，选择其他的sub cluster</li>
<li>Client挂了：跟原来的/ClientRMService/一样</li>
<li>通过policyFacade加载策略，根据context与blacklist为当前提交选择sub cluster；具体逻辑在<strong>FederationRouterPolicy.getHomeSubcluster</strong>  </li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-c6dbd82e45d5c69bd30b07e4f7e077a3_b.png" alt="img"></p>
<ul>
<li>同步提交任务至目标sub cluster</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-da2fa220baae8ba7238a1b77bebe009a_b.png" alt="img"></p>
<p><strong>疑问&amp;&amp;待确定的点</strong></p>
<ul>
<li>client —&gt; router —&gt; rm： 这条链路如果router挂了如何failover；<strong>在submitApplication方法上方有较为详细的边界情况处理解释</strong></li>
<li><strong>是否支持多个router？以及在配置中如何指定多个router？防止一个router挂掉的情况</strong></li>
<li><strong>需要确定是否有机制来维系真正存活的cluster，是否会动态摘除down掉的RM</strong></li>
</ul>
<h2 id="Policy-State-Store模块"><a href="#Policy-State-Store模块" class="headerlink" title="Policy State Store模块"></a>Policy State Store模块</h2><h3 id="FederationStateStoreFacade"><a href="#FederationStateStoreFacade" class="headerlink" title="FederationStateStoreFacade"></a>FederationStateStoreFacade</h3><ul>
<li>作为statestore的封装，抽象出一些重试和缓存的逻辑</li>
</ul>
<h3 id="FederationStateStore"><a href="#FederationStateStore" class="headerlink" title="FederationStateStore"></a>FederationStateStore</h3><ul>
<li>一般采用<strong>ZookeeperFederationStateStore</strong>的方式</li>
<li><strong>ZookeeperFederationStateStore</strong>  实现中，对应的数据存储结构如下  </li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-b4e79639629bdec688ec4efb6f9b275f_b.png" alt="img"></p>
<ul>
<li>通过心跳维系了RM是否是active；通过<strong>filterInactiveSubClusters</strong>来决定是否需要过滤存活的RM</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-1de1b20d5b5a5c01c26e6724695cf440_b.png" alt="img"></p>
<ul>
<li><strong>实例化过程</strong></li>
<li>加载配置<strong><em>yarn.federation.state-store.class</em></strong>：默认实现是<strong><em>MemoryFederationStateStore</em></strong></li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-e5888bd36c0c482c10c2bb22782ceb27_b.png" alt="img"></p>
<h3 id="SubClusterResolver"><a href="#SubClusterResolver" class="headerlink" title="SubClusterResolver"></a>SubClusterResolver</h3><ul>
<li>用来判断某个指定的node是属于哪个子集群的工具类;主要有getSubClusterForNode，getSubClustersForRack方法</li>
<li>实例化过程</li>
<li>加载配置yarn.federation.subcluster-resolver.class: 默认实现是DefaultSubClusterResolverImpl</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-cf9ebad47e5c250ef5a545ee4e1c1b05_b.png" alt="img"></p>
<ul>
<li>在<strong>load</strong>方法中，获取了machineList，定义list的地方是在一个文件中通过<strong>yarn.federation.machine-list</strong>获取文件位置；且文件中的内容格式如下</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-7d1685ce8602e9884412e42a9faaf72e_b.png" alt="img"></p>
<ul>
<li>解析文件之后，将machine依次添加到<strong>nodeToSubCluster</strong>，<strong>rackToSubClusters</strong>集合中</li>
</ul>
<h2 id="AMRMProxy模块"><a href="#AMRMProxy模块" class="headerlink" title="AMRMProxy模块"></a>AMRMProxy模块</h2><ul>
<li>看完client—&gt;rm侧的提交任务模块之后（<strong>router</strong>），接下来可以分析AM与RM侧的交互模块(<strong>AMRMProxy</strong>)  </li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-d90061b8beeb05e40586a3dada4222a7_b.png" alt="img"></p>
<ul>
<li>AMRMProxyService ：如上图所示，起于所有的NM之上的服务，作为AM与RM之间通信的代理；会将AM请求转发到正确的HomeSubCluster</li>
<li>FederationInterceptor: 作为AMRMProxyService中的拦截器，主要做AM与RM之间请求转发</li>
</ul>
<h3 id="AMRMProxyService-—-FederationInterceptor"><a href="#AMRMProxyService-—-FederationInterceptor" class="headerlink" title="AMRMProxyService — FederationInterceptor"></a>AMRMProxyService — FederationInterceptor</h3><ul>
<li>类比Router，FederationInterceptor作为AMRMProxy的请求拦截处理</li>
<li>在AM的视角，<strong>FederationInterceptor</strong>的作用就RM上的<strong>ApplicationMasterService</strong>；AM通过<strong>AMRMClientAsyncImpl</strong>或<strong>AMRMClientImpl</strong> 走RPC协议与<strong>AMRMProxyService</strong> 交互</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-0ec5e08fa702ab8a00bb11528da4b138_b.png" alt="img"></p>
<p><strong>registerApplicationMaster详解</strong></p>
<ul>
<li>按照正常的AM流程分析，由<strong>AMLauncher</strong>启动container之后须首先会调用<strong>registerApplicationMaster</strong>方法初始化权限信息以及将自己注册到对应的RM上去；对应到<strong>FederationInterceptor</strong>是如下方法</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-a322c31e9908ed4f8b08c05130c67688_b.png" alt="img"></p>
<ul>
<li>制造一种假象：RM永不会挂掉；有可能会因为超时或者RM挂掉等原因而导致发出多个重复注册的请求，此时都会返回最近一次成功的注册结果；所以这也就是为什么registermaster这个方法必须为线程安全的原因</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-e127ca2f6e0120575bc76c5b38126a43_b.png" alt="img"></p>
<ul>
<li>目前只是往HomeSubCluster上注册AM，而不会往其他子集群上注册。是为了不影响扩展性；即不会随着集群的增多AM呈线性扩展；应该是后续按需注册sub-cluster rm</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-571134517c85d3c6fd5a237412618a74_b.png" alt="img"></p>
<ul>
<li><strong>this.homeRMRelayer</strong>是具体的跟RM通信的代理，其创建方式在<strong>FederationInterceptor.init</strong>方法中</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-4afe5125de9a0e80a3440f6807e12e84_b.png" alt="img"></p>
<ul>
<li>最后在返回response之前，会根据作业所属的queue信息从statestore中获取对应的策略，并初始化<strong>policyInterpreter</strong></li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-bab165a60bd63a3c43549950825d28a0_b.png" alt="img"></p>
<h3 id="Allocate详解"><a href="#Allocate详解" class="headerlink" title="Allocate详解"></a>Allocate详解</h3><ul>
<li>周期性的通过心跳与HomeCluster和SubCluster RMs交互；期间可能伴随有SubCluster 上AM的启动和注册</li>
<li><strong>splitAllocateRequest</strong>：将原来的request重新构造成面向所有已经注册的sub-cluster rm request</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-bf455e34f88d53a7dcc5ffea1d51d8a9_b.png" alt="img"></p>
<ul>
<li>具体到实现：通过requestMap来放置clusterId与allocateRequest的对应关系；通过uamPool获取已经注册UAM的sub clusterId并构建request</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-3bb90c887c818638bb335ff6d46b9d46_b.png" alt="img"></p>
<ul>
<li>后面的步骤是根据所有已经注册的home cluster和sub cluster id构建release, ask, blacklist等请求</li>
<li>对于资源的请求拆分：这里会去调federation policy interpreter将原来request中的<strong>askList(Resource Request List)</strong>根据策略拆分到各个子集群；所以这里会涉及到Federation Policy调用，具体的分析接下来会单独拎出一小节解释</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-675411d4dfdc72c8d89ee301a8709b7c_b.png" alt="img"></p>
<ul>
<li>拿到<strong>asks</strong>后，会将<subclusterid, resourcerequestlist="">的对应关系，加入到<strong>requestMap</strong>中</subclusterid,></li>
<li><strong>注意：</strong>这里借助<strong>findOrCreateAllocateRequestForSubCluster</strong>方法实现如果requestMap中不存在asks中对应的subClusterId，会新new一个request塞入map；后续这个request会在对应的subCluster上启动<strong>UAM</strong></li>
<li><strong>因为对于新的job，刚开始确实是只在homeCluster上启动了AM</strong></li>
<li><strong>sendRequestsToResourceManagers</strong></li>
<li>splitAllocateRequest之后就是将构造好的请求发送到对应的cluster上；顺带在所有的subcluster启动UAM并注册上(如果之前没有启动的话)；返回值是所有新注册上的UAM</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-34f142d2135a9f8b12ae234966bde9b6_b.png" alt="img"></p>
<ul>
<li><strong>registerWithNewSubClusters</strong> 用来在其他子集群中创建新的UAM实例</li>
<li>在uamPool中不存在的被认为是新集群（<em>有点与<strong>splitAllocateRequest</strong>） 取AllUAMIds逻辑矛盾</em>）</li>
<li>对newSubClusters集合迭代，依次在subClaster上启动UAM，并注册UAM</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-1051b6772a9c893a910f3497cb9cc327_b.png" alt="img"></p>
<ul>
<li>最后针对不同的cluster，调用不同的clientRPC请求资源</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-2e0d3265a416a8bd9131559ce958b2f1_b.png" alt="img"></p>
<ul>
<li><strong>mergeAllocateResponses</strong></li>
<li>用于合并所有资源请求返回的allocateResponse。实现里面是对<strong>asyncResponseSink</strong>容器的迭代，而asyncResponseSink的写入是在HeartBeatCallback逻辑里的</li>
<li>对于allocateResponse的合并操作在<strong>mergeAllocateResponse</strong>中</li>
<li><strong>mergeRegistrationResponses</strong></li>
<li>是在注册完其他的sub cluster之后将UAM加入到最终合并的AllocateResponse中；主要是对allocatedContainers以及NMTokens集合做增加</li>
</ul>
<h3 id="finishApplicationMaster详解"><a href="#finishApplicationMaster详解" class="headerlink" title="finishApplicationMaster详解"></a>finishApplicationMaster详解</h3><ul>
<li>结束任务的时候有点类似allocate，需要向所有的sub cluster发送finish请求；目前是丢到一个compSvc线程池中批量执行*finshApplicationMaster</li>
<li>在线程池中执行sub cluster finish的同时，也会调用home cluster rm进行finish操作</li>
</ul>
<h2 id="Federation-Policy模块"><a href="#Federation-Policy模块" class="headerlink" title="Federation Policy模块"></a>Federation Policy模块</h2><ul>
<li>federation policy模块通过FederationPolicyManager的接口实现来统一加载</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-6a2db128fc5762aba3591cf4912bfc40_b.png" alt="img"></p>
<ul>
<li><strong>FederationPolicyInitializationContext</strong>：初始化FederationAMRMProxyPolicy和FederationRouterPolicy的上下文类</li>
<li><strong>federationStateStoreFacade</strong>: policy state strore的具体实现实例</li>
<li><strong>federationPolicyConfiguration</strong>: 具体的策略配置</li>
<li><strong>federationSubclusterResolver</strong>：用来判断某个指定的node是属于哪个子集群的工具类</li>
<li><strong>homeSubcluster</strong>：当前application实际AM运行的集群ID</li>
</ul>
<h2 id="Policy-具体的实现列举"><a href="#Policy-具体的实现列举" class="headerlink" title="Policy 具体的实现列举"></a>Policy 具体的实现列举</h2><h3 id="amrmproxy模块的policy实现"><a href="#amrmproxy模块的policy实现" class="headerlink" title="amrmproxy模块的policy实现"></a>amrmproxy模块的policy实现</h3><ul>
<li><strong>LocalityMulticastAMRMProxyPolicy</strong></li>
<li>\1. 如果是有偏好的host的话，会根据<em>SubClusterResolver</em> resolve cluster的结果转发到对应的cluster，但如果没有resolve的话，会默认将请求转向home cluster</li>
<li>\2. 如果有机架的限制，策略同上</li>
<li>\3. 如果没有host/rack偏好的话，会根据<em>weights</em>转发到对应的集群；weights的计算根据<em>WeightedPolicyInfo</em>以及<em>headroom</em>中的信息</li>
<li>\4. 所有请求量为0的请求都会转发到所有我们曾经调度过的子集群中（以防用户在尝试取消上一次的请求）</li>
<li>注：该实现始终排除当前未活跃的RM</li>
<li><strong>具体实现细节待深究</strong></li>
</ul>
<p><strong>router模块的policy实现</strong></p>
<ul>
<li>总体来说router端的策略偏简单，自己定制也容易</li>
<li>默认实现是<strong>UniformRandomRouterPolicy</strong>，随机转发client请求到某个alive的cluster</li>
</ul>
<h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><ul>
<li>在NM侧，不能开启<strong>FederationRMFailoverProxyProvider</strong>，这个统一在获取RMAddress逻辑上有不足，导致NM启动时拿到的RMAddress是localhost无法通过ResourceTracker连上RM，最终注册失败</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-edc97c0d9ba93b9094e561e6cd7b5464_b.png" alt="img"></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-11-04T17:38:28.000Z">2019-11-05</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    15 分钟 读完 (大约 2236 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/11/05/Hadoop-Rpc源码分析/">Hadoop Rpc源码分析</a>
            
        </h1>
        <div class="content">
            <p>Hadoop生态系统中Rpc底层基本都是走的一套实现，所以有必要对Rpc底层实现做一次系统性的梳理总结。<br><a href="https://zhuanlan.zhihu.com/p/88768710" target="_blank" rel="noopener">知乎链接</a></p>
<p><strong>Client&amp;Server实现入口</strong></p>
<p>RpcEngine作为Rpc实现的接口，用来获取client端proxy和server端的server</p>
<ul>
<li>主要的实现是WritableRpcEngine，ProtobufRpcEngine（现默认），两者的区别主要是序列化与反序列化的协议不同；内部都有继承Server构成完整Rpc Server的实现类</li>
<li>IPC.Server是两种序列化协议的基类，org.apache.hadoop.ipc.Server 主要实现了Reactor的请求处理模式</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-c8db58fa71163284be19a5ef5d18226b_b.jpg" alt="img"></p>
<h2 id="Client-amp-Server-构造方式"><a href="#Client-amp-Server-构造方式" class="headerlink" title="Client &amp; Server 构造方式"></a>Client &amp; Server 构造方式</h2><ul>
<li>按照序列化协议区分两种实现：ProtobufRpcEngine, WriteableRpcEngine</li>
<li>通过接口getProxy 构造RpcClient</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-88bd21ee56a1cd64a95d970c67c743a5_b.jpg" alt="img"></p>
<p><img src="https://pic1.zhimg.com/v2-92891b943d699abd3dbb68332be7c6e4_b.jpg" alt="img"></p>
<p><img src="https://pic2.zhimg.com/v2-1a71694dbcf4d96672256ed37fa33cf9_b.jpg" alt="img"></p>
<ul>
<li>getServer构造RpcServer</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-7ea92e7484f556a3f658e79a751e19a1_b.jpg" alt="img"></p>
<h3 id="RPC-Client剖析"><a href="#RPC-Client剖析" class="headerlink" title="RPC Client剖析"></a>RPC Client剖析</h3><p>总体来说Client端实现比较简单，用hashTable的结构来维护connectionId -&gt; connections以及callId -&gt; calls 对应关系，使得请求响应不需要有严格的顺序性</p>
<ul>
<li>Ipc.Client构成</li>
<li>callIdCounter：callId 发号器</li>
<li>rpc_client.png: HashTable结构，用来维护Id → Connection的映射</li>
<li>sendParamsExecutor：请求发送线程池    </li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-9b923f98235d7881f79f9525f2a025f5_b.jpg" alt="img"></p>
<ul>
<li>Connection：自身是一个线程</li>
<li>calls: HashTable结构，请求结束将从call从HashTable中移除</li>
<li>sendRpcRequest：用户线程中通过call入口调用，用户线程阻塞</li>
<li>receiveRpcResponse:  run中不断轮询server看结果是否就绪</li>
<li>client 处理过程</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/rpc_client.png" alt="img"></p>
<ul>
<li>通过反射获取到方法描述，走client Invoker调用远程实现</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-a73c35b6ffe44b32f40f638f110d0ac6_b.jpg" alt="img"></p>
<ul>
<li>getConnection中与远程server 建立socket 连接，并将连接加入connections集合中</li>
<li>在用户线程中调用connection.sendRpcRequest，阻塞的获取结果</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-9ace991f5df04fde6559437de1e46402_b.jpg" alt="img"></p>
<ul>
<li>Connection自身run方法中不停的轮询Server接收返回结果</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-d4ebd6403c80e86bb7ea7acff2b3e643_b.jpg" alt="img"></p>
<ul>
<li>waitForWork用来判断当前connection是否应该继续存在，返回true则继续轮询server，如果是false则关闭当前connection</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-c46e3a852373a74fa752a8b1edfe176f_b.jpg" alt="img"></p>
<ul>
<li><strong>receiveRpcResponse</strong>接收服务端返回结果，将calls移除table，可以乱序，通过ConnectionId索引，<strong>不需要同步代码块，因为只有一个receiver</strong></li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-347d4bb3e5d6bafe471a1b8e686343e8_b.jpg" alt="img"></p>
<h3 id="RPC-Server剖析"><a href="#RPC-Server剖析" class="headerlink" title="RPC Server剖析"></a>RPC Server剖析</h3><ul>
<li>Server端采用经典的Reactor模式，利用IO多路复用实现事件驱动</li>
<li>痛点在于多路复用之前的处理模式，socket read/write是阻塞的，一个线程只能处理一个socket；使用selector之后一个进程可以监视多个进程文件描述符</li>
</ul>
<p>参考阅读：<a href="https://www.cnblogs.com/crazymakercircle/p/9833847.html" target="_blank" rel="noopener">Reactor模式</a>、<a href="https://www.cnblogs.com/crazymakercircle/p/10225159.html#4310290" target="_blank" rel="noopener">Java  NIO   底层原理 </a> 、<a href="https://www.jianshu.com/p/dfd940e7fca2" target="_blank" rel="noopener">select、poll、epoll</a></p>
<p><img src="https://pic1.zhimg.com/v2-58df22a9108b9c724c8b757f6357d8c4_b.jpg" alt="img"></p>
<p>图片摘自《Hadoop技术内幕：深入解析MapReduce架构设计与实现原理 》</p>
<ul>
<li>Reactor 工作图</li>
<li>Reactor：负责响应IO事件，将事件派发到工作线程</li>
<li>Acceptor：用来接收Client端的请求，建立Client与handler的联系；向Reactor注册handler</li>
<li>Reader/Sender：为了加快速度，同时做到请求和处理过程的隔离，reader和sender 分别是两个线程池，用来存放该过程处理完后的连接，处理完之后塞入中间队列，等待下一个过程的线程拿去处理就行</li>
<li>Handler：connection对应的工作线程，会做一些decode, compute, encode工作</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-64e02ba7cce407bf7d191ce4b08bfdeb_b.jpg" alt="img"></p>
<p><strong>Hadoop RpcServer组成结构</strong></p>
<ul>
<li><strong>序列化层</strong>：RpcRequestWrapper, RpcResponseWrapper</li>
<li><strong>接口调用层</strong>：RpcInvoker，通过反射方式阻塞调用Server端具体的Service方法；调用前后记录一些metrics信息</li>
<li>在handler线程处理逻辑中，通过注册的rpcKind获取对应的RpcInvoker实现，通过反射来调用工作层的Service</li>
<li><strong>请求接收/返回层Ipc.Server</strong>：基于Java NIO实现的Reactor 事件驱动模式</li>
<li>Listener</li>
<li>selector：监听请求 → 建立连接 → 派发到Reader线程</li>
<li>Readers</li>
<li>readSelector：解析&amp;封装Call → 塞入CallQueue </li>
<li>Handlers：工作线程</li>
<li>并行pull CallQueue，调用RpcInvoker处理</li>
<li>Responder：read request和write response采用不同的selector实现读写分离</li>
<li>writeSelector</li>
<li>connectionManager: 定时清理idle时间过长的Connection</li>
<li>CallQueue：reader handler之间的缓冲队列，<strong>生产消费者模型</strong></li>
</ul>
<h3 id="RPC-Server-处理流程"><a href="#RPC-Server-处理流程" class="headerlink" title="RPC Server 处理流程"></a>RPC Server 处理流程</h3><p><img src="https://pic2.zhimg.com/v2-38a1ef7504f6e74ba8bb4aa3a0a1bdb5_b.jpg" alt="img"></p>
<ul>
<li>Listener → Reader 请求建立过程：Listener<em>Reader</em>Connection</li>
<li>Listener线程只有一个，通过Selector方式监听客户端的Rpc请求(OP_ACCEPT事件)，调用doAccept方法建立连接；此时connectionManager线程开始工作</li>
<li>建立连接后，roundbin方式获取一个reader线程，将连接塞入reader线程的pending队列和connectionManager中</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-3d7ddb917b9a9bba707c2208e9b71c4f_b.jpg" alt="img"></p>
<p><img src="https://pic4.zhimg.com/v2-fb8edf28b12530ea9f49ce030d780f7b_b.jpg" alt="img"></p>
<ul>
<li>Reader线程doRunLoop中，将pending的connections注册到readSelector中，用来监听一个connection读就绪事件</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-c3056224c1b460860b0b9c26c2ccc182_b.jpg" alt="img"></p>
<ul>
<li>数据读入 → 工作线程 : Reader<em>Connection</em>CallQueue</li>
<li>而后Reader通过selector方式，只要监听的channel有读事件，则调用doRead方法；其中通过selectionKey获取关联的connection对象，调用connection的readAndProcess方法</li>
<li>connection.readAndProcess: 主要是将channel里面的数据读入data byteBuffer中，数据读完之后调用processOneRpc 进一步处理</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-01d207ac87060718231e7d6a32599412_b.jpg" alt="img"></p>
<p><img src="https://pic4.zhimg.com/v2-74ff999fb2c4844c9470e9d3bfefa943_b.jpg" alt="img"></p>
<ul>
<li>connection. processOneRpc 对buffer decode构造成DataInputStream以及RpcHeader（请求元信息，协议类型等）通过processRpcRequest将请求塞入CallQueue中，等待handlers处理</li>
<li>connection.processRpcRequest：通过header中指定的rpc engine将dataInputStream根据不同engine反序列化协议反序列化成rpcRequestWrapper；构造Call对象塞入CallQueue, 并incrRpcCount</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-46cd9573bbe1ffd820a5a22ca16628d9_b.jpg" alt="img"></p>
<p><img src="https://pic1.zhimg.com/v2-195514acc9cc988cd2b7c14f45a535d4_b.jpg" alt="img"></p>
<ul>
<li>Handler → RpcInvoker → Responder</li>
<li>Handler线程在Server start的时候就已经构建启动了</li>
<li>并行pull callQueue获取队列中未处理的call，调用call方法</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-cc649767778d9769384fde11b8b7a5c0_b.jpg" alt="img"></p>
<ul>
<li>通过rpcKind获取对应的RpcInvoker实现；主看ProtoBufRpcInvoker.call</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-07fc870601bd5199e9c298828106c598_b.jpg" alt="img"></p>
<ul>
<li>通过反射获取server端对应的接口实现，阻塞调用，在调用前后记录一些metrics信息；最后将结果包装成RpcResponseWrapper</li>
</ul>
<p><img src="https://pic2.zhimg.com/v2-2c1300aac072c27f7a7f6d02326643d5_b.jpg" alt="img"></p>
<p><img src="https://pic3.zhimg.com/v2-10f7ea1450e7fcba8eeba0b28cfade16_b.jpg" alt="img"></p>
<ul>
<li>当结果处理完成之后，通过setupResponse将结果序列化成byte buffer根据不同engine实现的wrapper 序列化方式有所不同</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-ced2fa047079e775740313b85008ea2b_b.jpg" alt="img"></p>
<p><img src="https://pic3.zhimg.com/v2-0ec60ac2232816c3d38b72ce5ac1c02e_b.jpg" alt="img"></p>
<ul>
<li>调用Responder.doRespond将请求结果返回客户端</li>
<li><strong>请求返回处理过程:</strong>  通过Responder线程+ writeSelector</li>
<li>Responder.doRespond</li>
<li>在handler中尽可能的将response一次性写入channel buffer，如果没有剩余则不用注册Responder的Responder.doRespond</li>
<li>如果一次性写不完且是在handler线程中，则唤醒writeSelector，将当前channel 注册 SelectionKey.OP_WRITE 异步去处理</li>
</ul>
<p><img src="https://pic4.zhimg.com/v2-3b339c9e8e15060518996edccee9aebf_b.jpg" alt="img"></p>
<ul>
<li>Responder 线程自身的doRunLoop里面也是通过writeSelector监听OP_WRITE事件处理</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-7c4c403ee9bff19653e58088d81d7428_b.jpg" alt="img"></p>
<ul>
<li><strong>CallQueueManager</strong> 相关</li>
<li>默认实现是LinkedBlockingQueue</li>
<li>大小通过queueSizePerHandler或ipc.server.handler.queue.size * handler_count 决定</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-56e6f38dd99dc26c8dbe3ccb84a581aa_b.jpg" alt="img"></p>
<ul>
<li><strong>ConnectionManager相关</strong>：用来定时清理idle时间过长的connection</li>
<li>idleScanThreshold: 每次轮询扫描的connections 阈值default 4000</li>
<li>idleScanInterval: 定时检测线程轮询间隔 default 10000</li>
<li>maxIdleTime:  一个connection最长idle时间，default 2* 10000</li>
<li>maxIdleToClose : 一次轮询最多关闭的连接数 default 10</li>
<li>一个connection是不是可以被清理由以下条件决定</li>
<li>connection.isIdle(): rpcCount为0, 也就是Call没有塞入callQueue；在connection.processRpcRequest末尾，如果成功塞入callQueue中的话会incrRpcCount</li>
<li>lastContact &lt; minLastContact: </li>
<li>minLastContact:  Time.now() - maxIdleTime</li>
<li>startIdleScan：开启清理线程，随Listener线程启动</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-06-10T05:08:55.000Z">2019-06-10</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    20 分钟 读完 (大约 3036 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/06/10/【Spark源码分析】Job提交执行过程详解/">【Spark源码分析】Job提交执行过程详解</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近恰好有点时间梳理一下整个Spark job提交执行流程的相关源码。首先，给一个总的代码流程图（在Executor那块还需补充完整），方便理解整个处理逻辑</p>
<p><img src="https://pic3.zhimg.com/80/v2-6e794771cf2317012b3986ed35979476_hd.jpg" alt=""></p>
<h2 id="Spark-Job-提交处理过程源码解析"><a href="#Spark-Job-提交处理过程源码解析" class="headerlink" title="Spark Job 提交处理过程源码解析"></a>Spark Job 提交处理过程源码解析</h2><h3 id="submitJob解析"><a href="#submitJob解析" class="headerlink" title="submitJob解析"></a>submitJob解析</h3><ul>
<li>macos IntelliJ 中 command+7 查看DagScheduler所有方法，从submitJob方法开始分析，提交了JobSubmitted事件进事件队列，等待处理</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job1.png" alt=""></p>
<ul>
<li>在<strong>DagScheduler</strong>中有<strong>DAGSchedulerEventProcessLoop</strong>类，主要用来集中分发处理事件队列中的事件</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job2.png" alt=""></p>
<ul>
<li>移步DagScheduler.handleJobSubmitted方法，更新UI数据，同时调用submitStage方法；这里finalStage是createResultStage这个方法从最后一个stage生成所有stage的过程</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job3.png" alt=""></p>
<h3 id="submitStage解析"><a href="#submitStage解析" class="headerlink" title="submitStage解析"></a>submitStage解析</h3><p><img src="http://jacobs.wanhb.cn/images/spark-job4.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job5.png" alt=""></p>
<p>可以看到<strong>getOrCreateParentStages</strong>方法中只有shuffle操作时才会创建新的stage</p>
<ul>
<li>再来看SubmitStage方法实现细节，看之前如果对spark运行有了解的话，也大概知道，submitStage里面是提交task的细节</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job6.png" alt=""></p>
<p>这里先判断几个集合：<strong>waitingStages,runningStages,failedStages</strong>中是否已经存在该stage，防止重复提交stage；通过<strong>getMissingParentStages</strong>，深度遍历地从后往前判断当前stage是否存在需要重新计算的stage，加入<strong>missing stages</strong>集合中。那么什么条件下才算是一个missing stage呢？我们来分析<strong>getMissingParentStages</strong>实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job7.png" alt=""></p>
<p>可以发现判断当前rdd是否被cache了是通过DagScheduler.getCacheLocs获取缓存的location，观察到cacheLocs的数据结构是一个HashMap，key为rdd id，value为TaskLocation集合；虽说HashMap是个非线程安全集合，不过这里写操作线程安全通过加锁实现，所以说用HashMap实现倒也无妨</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job8.png" alt=""></p>
<p>这个集合是在getCacheLocs中写入的</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job9.png" alt=""></p>
<p>如果当前rdd本身没有设置storage level的话，也就无需查找缓存了，直接返回，否则通过blockManagerMaster.getLocations查找具体block对应的位置；blockManagerMaster上存储了所有Executor汇报上来的所有block位置元数据信息<strong>（后面有一小节来分析block的写入和上报过程）</strong></p>
<p>接着，对于rdd如果没有显式缓存的情况，需要遍历rdd所有的依赖，对于是宽依赖的stage，调用<strong>getOrCreateShuffleMapStage</strong>获取或者创建mapStage，通过isAvailable判断所有output是否都已经准备好，isAvailable是通过查询<strong>mapOutputTracker</strong>已经注册的task output信息得到的，对于isAvailable为false的情况，说明output没有，或丢失。需要重新计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Number of partitions that have shuffle outputs.</span><br><span class="line">   * When this reaches [[numPartitions]], this map stage is ready.</span><br><span class="line">   */</span><br><span class="line">  def numAvailableOutputs: Int = mapOutputTrackerMaster.getNumAvailableOutputs(shuffleDep.shuffleId)</span><br><span class="line">  /**</span><br><span class="line">   * Returns true if the map stage is ready, i.e. all partitions have shuffle outputs.</span><br><span class="line">   */</span><br><span class="line">def isAvailable: Boolean = numAvailableOutputs == numPartitions</span><br></pre></td></tr></table></figure>
<h3 id="submitMissingTasks解析"><a href="#submitMissingTasks解析" class="headerlink" title="submitMissingTasks解析"></a><strong>submitMissingTasks解析</strong></h3><ul>
<li>接下来分析submitStage中submitMissingTasks实现，这个方法是根据需要计算的stage来提交stage中的taskset。taskIdToLocation获取task要处理的数据的所在节点</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job10.png" alt=""></p>
<p>然后根据task所属的stage类型来创建实际的task实例(ShuffleMapTask与ResultTask)</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job11.png" alt=""></p>
<p>最后如果待计算的tasks集合不为空，则通过taskScheduler引用将task set提交到TaskScheduler中去调度</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job12.png" alt=""></p>
<p>具体看<strong>TaskSchedulerImpl.submitTasks</strong>实现，首先会创建一个<strong>TaskSetManager</strong>。<strong>TaskSetManager</strong>实际调度TaskSet的的实现，跟踪并且根据数据优先级分发task，以及重试失败的task。因为一个stage同一时刻只能有至多一个<strong>TaskSetManager</strong>处于活跃状态，所以创建完<strong>TaskSetManager</strong>实例之后，需要将Stage中其他<strong>TaskSetManager</strong>实例标记为<strong>Zombie</strong>状态</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job13.png" alt=""></p>
<p>随后，根据运行模式来判断要不要启动资源分配情况是否是饥饿状态的监控线程，最后调用<strong>CoarseGrainedSchedulerBackend.reviveOffers()</strong> 方法开始task调度</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job14.png" alt=""></p>
<p>实际上是发了一个actor消息，直接看receive中针对ReviveOffers消息的处理方法(<strong>CoarseGrainedSchedulerBackend.makeOffers</strong>)实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job15.png" alt=""></p>
<h3 id="Scheduler-resourceOffers解析"><a href="#Scheduler-resourceOffers解析" class="headerlink" title="Scheduler.resourceOffers解析"></a>Scheduler.resourceOffers解析</h3><ul>
<li>先筛选出存活的executor，然后调用TaskSchedulerImpl.resourceOffers方法开始为每个TaskSet中的task分配具体执行节点</li>
<li>在分配前将那些之前被加入黑名单又重新生效的节点包括进来；然后打散workerOffer集合，防止task分配不均</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job16.png" alt=""></p>
<ul>
<li>获取shuffleOffer中节点剩余cpu以及slot(cores/CPU_PER_TASK(default 1))集合availableCpus，availableSlots</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</span><br><span class="line">val availableSlots = shuffledOffers.map(o =&gt; o.cores / CPUS_PER_TASK).sum</span><br></pre></td></tr></table></figure>
<ul>
<li><p>获取sortedTaskSets，在循环期间随时关注是否有新的executor加入</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job17.png" alt=""></p>
</li>
<li><p>对sortedTaskSets集合的每个taskSet，如果taskSet是barrier模式，且可用slot小于taskSet中的task数量，则直接跳过分配；因为barrier模式中，所有的task都需要并行启动</p>
</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job18.png" alt=""></p>
<ul>
<li>对于非barrier模式的taskSet，根据taskSet中所有tasks的数据优先级调度task。如下图，myLocalityLevels是taskSet中所有tasks数据本地性优先级集合。由TaskSetManager. computeValidLocalityLevels方法计算得到</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job19.png" alt=""></p>
<ul>
<li>优先级从高到低依次为<strong>PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</strong> 也是按照这个顺序优先调度task</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job20.png" alt=""></p>
<ul>
<li><p>具体的调度见<strong>TaskSchedulerImpl.resourceOfferSingleTaskSet</strong>方法，里面实际依赖<strong>TaskSetManager.resourceOffer</strong>方法</p>
</li>
<li><ul>
<li>首先对应的executor不能是被拉入黑名单，且当前TaskSetManager不能被标记为zombie</li>
<li>从taskSet中出队一个指定locality的 task（实现见TaskSetManager.dequeueTask）加入runningTasks结合中。对于非barrier模式的stage来说，只要有task被调度成功了就可以跑起来</li>
</ul>
</li>
<li><p>这里再回过头看CoarseGrainedSchedulerBackend.makeOffers实现。当调用scheduler.resourceOffers之后如果有TaskDescription集合返回的的话，就可以调用launchTasks了</p>
</li>
<li><ul>
<li>在launchTasks方法中，发送了LaunchTask消息，将序列化的Task信息通过rpc发送给Executor端（CoarseGrainedExecutorBackend实现）</li>
<li><img src="http://jacobs.wanhb.cn/images/spark-job22.png" alt=""></li>
</ul>
</li>
<li><p>看CoarseGrainedExecutorBackend.receive中对LaunchTask消息的处理逻辑</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job23.png" alt=""></p>
</li>
<li><p>executor.launchTask中，实例化了TaskRunner，并将taskRunner提交到线程池中调度执行。<strong>具体的执行逻辑在下一个小节描述</strong></p>
</li>
</ul>
<h2 id="ShuffleMapTask-block写入过程分析"><a href="#ShuffleMapTask-block写入过程分析" class="headerlink" title="ShuffleMapTask block写入过程分析"></a><strong>ShuffleMapTask block写入过程分析</strong></h2><ul>
<li>在上文中，我们分析到了TaskRunner。直接跳到TaskRunner里面的run方法实现</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job25.png" alt=""></p>
<p>可以看到通过执行执行task.run方法拿到执行task后的结果，跟进去看结果是什么数据结构。</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job26.png" alt=""></p>
<p>发现调用了runTask方法，查看接口的定义，发现有多个实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job27.png" alt=""></p>
<p>看到了熟悉的<strong>ShuffleMapTask</strong>,<strong>ResultTask</strong>字眼，结果明朗了，其实就是根据宽窄依赖来调用具体的Task实现。<strong>ResultTask</strong>生成的result是func在rdd各个partition上的执行结果而<strong>ShuffleMapTask</strong>生成的result是shuffle 文件输出信息(<strong>MapStatus</strong>)</p>
<ul>
<li>我们选<strong>ShuffleMapTask.runTask</strong>实现分析，返回的数据结构是<strong>MapStatus，MapStatus</strong>封装了task 所在的blockManager的信息（executorId+host+port）以及map task到每个reducer task的输出FileSegment的大小</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job28.png" alt=""></p>
<p>来分析outputFile的实现细节，首先这里需要获取具体的ShuffleWriter实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job29.png" alt=""></p>
<p>每个shuffleId对应的ShuffleHandle（也即是ShuffleWriter实现）由ShuffleManager统一管理，通过registerShuffle注册具体的ShuffleWriter</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job30.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job31.png" alt=""></p>
<p>如图所示，目前spark中的shuffleWriter实现大概有三种，这里不详细比较，后续有专门文章分析Spark ShuffleWriter实现；选最常用的<strong>SortShuffleWriter.write</strong> 实现深入分析MapStatus产生过程</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job32.png" alt=""></p>
<p>可以看到SortShuffleWriter对于每个mapTask只会产生一个output，通过indexfile start和end offset 来计算后续reduceTask获取数据的位置，这样做大大减小了output 文件数量。最终返回mapStatus结果</p>
<ul>
<li><p><a href="https://link.zhihu.com/?target=http%3A//%E4%BA%8E%E6%98%AF%E7%8E%B0%E5%9C%A8%E7%9F%A5%E9%81%93%E8%B0%83%E7%94%A8TaskRunner.run" target="_blank" rel="noopener">于是现在知道调用TaskRunner.run</a> 根据task的类型不同返回的结果也是不同的，统一将其包装成DirectResult发送到driver上；这里根据实际得到的resultSize有不同的处理情况</p>
</li>
<li><ul>
<li>如果result比较大，超过了maxDirectResultSize则会先把result存到本地的blockManager托管，storageLevel是内存+磁盘，然后把存储信息封装成IndirectTaskResult发送给driver</li>
<li>否则直接将序列化的result发送给driver。通过statusUpdate封装StatusUpdate事件将result发送给driver端处理</li>
<li><img src="http://jacobs.wanhb.cn/images/spark-job33.png" alt=""></li>
</ul>
</li>
<li><p>这里可以再分析一下result过大，blockManager是如何处理的细节。先看<strong>blockManager.doPutBytes</strong>，这里可以看到优先将result写入本地内存(LinkedHashMap实现)，如果内存不够<strong>（totalSize&gt;memory*spark.storage.memoryFraction）</strong>，则会将result通过diskStore直接写入磁盘</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job34.png" alt=""></p>
</li>
<li><p>看CoarseGrainedSchedulerBackend中具体处理StatusUpdate的实现，这里其实嵌套的比较多。按正常的路径首先会经过<strong>taskResultGetter.enqueueSuccessfulTask</strong>方法，在这里会将result反序列化（有<strong>DirectTaskResult</strong>与<strong>IndirectTaskResult</strong>之分），接着调用<strong>DagScheduler.handleSuccessfulTask</strong>。这里按照task类型不同有不同的处理方式：</p>
<ul>
<li><p>task是ResultTask的话，可以使用ResultHandler对result进行driver端计算（比如count()会对所有ResultTask的result做sum）</p>
</li>
<li><p>如果是ShuffleMapTask的话会注册mapOutputTracker，方便后续reduce task查询，然后submit 下一个stage</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job35.png" alt=""></p>
</li>
</ul>
</li>
</ul>
<h2 id="Rdd-Cache的过程"><a href="#Rdd-Cache的过程" class="headerlink" title="Rdd Cache的过程"></a>Rdd Cache的过程</h2><ul>
<li><p>分析至此，我们似乎还没看到ShuffleMapTask cache的过程，只知道如果是ResultTask产生的数据会优先塞入内存（不够溢写磁盘）。那么我们在平时操作中调用的rdd.cache在哪个环节起作用了呢？其实我们分析ShuffleMapTask处理过程时，忽略了一块代码（ShuffleMapTask.runTask 中 rdd.iterator的调用）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ShuffleMapTask.runTask</span><br><span class="line">=&gt; writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]])</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入iterator实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Rdd.iterator</span><br><span class="line">=&gt; getOrCompute (if storageLevel != StorageLevel.NONE)</span><br><span class="line">=&gt; computeOrReadCheckPoint (if storageLevel == StorageLevel.NONE)</span><br></pre></td></tr></table></figure>
</li>
<li><p>发现这里获取rdd的时候取决于当前rdd的存储方式，默认应该是<strong>StorageLevel.NONE</strong>，显示调cache的话将会走<strong>getOrCompute</strong>读取缓存逻辑，先看rdd不缓存的情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RDD.computeOrReadCheckpoint</span><br><span class="line">=&gt; 如果被checkpoint了，读checkpoint数据</span><br><span class="line">=&gt; 如果没有则直接重新计算</span><br></pre></td></tr></table></figure>
<p>如果有checkpoint会获取，否则直接compute重新计算rdd。看<strong>getOrCompute</strong>实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job38.png" alt=""></p>
<ul>
<li>核心还是调用从blockManager中去拿缓存的rdd或者重新计算更新blockManager，在getLocalValues方法里面会根据当前的StorageLevel到memory或者diskStore里面去拿blockResult，发现diskStore.getBytes实现里面，<strong>diskManager.getFile</strong>方法正是SortShuffleWriter中获取output路径的底层实现</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DiskStore.getBytes</span><br><span class="line">=&gt; val file = diskManager.getFile(blockId.name)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SortShuffleWriter.write</span><br><span class="line">=&gt; val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)</span><br><span class="line">IndexShuffleBlockResolver.getDataFile</span><br><span class="line">	 =&gt;blockManager.diskBlockManager.getFile(ShuffleDataBlockId(shuffleId, mapId, NOOP_REDUCE_ID))		 </span><br><span class="line">     =&gt;DiskManager.getFile</span><br></pre></td></tr></table></figure>
</li>
<li><p>经过一番分析，也能看出，cache主要适用于数据量不大的且反复使用的rdd；如果数据量过大，会发生频繁的数据溢写，还可能导致OOM的错误，收益大于成本，需要慎用</p>
</li>
<li>至此，shuffleMapTask从提交到输出到磁盘，以及DagScheduler如何处理Task Completion事件分析完了。后续文章中将分析ResultTask如何从<strong>mapOutputTracker</strong>拉取数据，以及如何计算的逻辑</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-06-02T05:31:16.000Z">2019-06-02</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 分钟 读完 (大约 389 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/06/02/【Spark源码分析】Broadcast/">【Spark源码分析】Broadcast</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Spark的broadcast机制本意在于两表做join时，如果其中某一个表足够的小，且又不是join的基表时（left或right join），可以将小表通过网络全量分发到各个executor节点上；通过在各个分区本地做join的方式来减少一次shuffle带来的开销</p>
<h2 id="Broadcast-原理"><a href="#Broadcast-原理" class="headerlink" title="Broadcast 原理"></a>Broadcast 原理</h2><h3 id="满足broadcast-join的条件源码分析"><a href="#满足broadcast-join的条件源码分析" class="headerlink" title="满足broadcast join的条件源码分析"></a>满足broadcast join的条件源码分析</h3><ul>
<li>来看SparkStrategies.scala文件</li>
<li><p>Broadcast 策略入口 broadcastSideBySizes<br><img src="http://jacobs.wanhb.cn/images/spark-broadcast1.png" alt=""></p>
<ul>
<li><p>可以发现broadcast 左表或者是右表是根据两个策略来控制的：canBuildLeft/canBuildRight， canBroadcast；</p>
</li>
<li><p>canBroadcast控制的是数据大小是否符合参数设定<br><img src="http://jacobs.wanhb.cn/images/spark-broadcast2.png" alt=""></p>
</li>
<li><p>canBuildLeft/canBuildRight是判断被广播的表是否作为left或right join基表的情况；如果作为基表的话是不能被broadcast的；当然Inner join不用管是不是基表<br><img src="http://jacobs.wanhb.cn/images/spark-broadcast3.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/spark-broadcast4.png" alt=""></p>
</li>
</ul>
</li>
<li><p>基表不能被广播的原因</p>
<ul>
<li><p>left/right join 之所以基表不能broadcast是因为这样做会破坏left join语义，产生重复的数据(比如广播了n份基表，因为最后都要保留基表的数据，不管有没有匹配上，所以会导致归并的时候有重复的情况)</p>
</li>
<li><p>翻阅其他博客对broadcast的解释，也能发现基表不能被广播的事实 <a href="https://www.iteblog.com/archives/2086.html" target="_blank" rel="noopener">Spark SQL中Join常用的几种实现</a> </p>
<p><img src="http://jacobs.wanhb.cn/images/spark-broadcast5.png" alt=""></p>
</li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-26T05:46:21.000Z">2019-05-26</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1470 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/26/【Spark源码分析】Dynamic-Resource-Allocation设计的思考/">【Spark源码分析】Dynamic Resource Allocation设计的思考</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在用spark的dynamicAllocation时发现：如果一个executor超过了设置的executorIdleTimeout时间，触发了回收策略，停止executor之后在sparkUI上会显示该executor的状态为Dead的情况</p>
<p>这引起了我的疑问，因为凭我自身的经验判断会误以为这个executor是一种<strong>被动退出</strong>的情况；也即是executor进程因为某种原因被nodemanager kill了，导致driver将这个executor状态置为dead并进行一系列的清理工作。而如果是dynamicAllocation的话，我认为是一种<strong>主动退出</strong>的情况，是安全的。spark自身系统设计不应该将这两个概念的状态笼统的用一个Dead来混淆视听</p>
<p>本着对真理追求到底的态度，我决定对sparkUI统计数据的来源这块代码逻辑进行梳理，以给自己提出的问题寻求答案</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><h4 id="Spark-UI-Server启动"><a href="#Spark-UI-Server启动" class="headerlink" title="Spark UI Server启动"></a>Spark UI Server启动</h4><ul>
<li><p>我们知道启动一个spark application之后相应的也会启动一个sparkUI server，用于实时监控展示 jobs，stages， executors等一些统计信息，那这些统计数据来自哪里呢？spark内部通过LiveListenerBus实现了一种监听订阅的模式，application内部所有的变更状态通过发布变更事件，交由订阅这些变更事件的实现去处理（这里称之为spark listener）。处理完之后的最新状态将反应在sparkUI上。</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-1.jpeg" alt=""></p>
</li>
<li><p>从图中我们可以看出DAGSchedule是主要产生各类SparkListenerEvent的起源，SparkListenerEvent通过ListenerBus事件队列，期间定时器匹配将事件匹配到不同的SparkListener实现上去</p>
</li>
</ul>
<h4 id="Executor页面渲染"><a href="#Executor页面渲染" class="headerlink" title="Executor页面渲染"></a>Executor页面渲染</h4><ul>
<li><p>在SparkUI的初始化方法中可以看到绑定了我们在界面中见到的几个Tab，如Executors，stages，storage等</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-2.png" alt=""></p>
<p>跟进ExecutorsTab中看具体的页面渲染逻辑</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-3.png" alt=""></p>
<p>整个代码层次分明，页面渲染包括页面顶部通用的bar以及body里面具体的内容，这里将渲染页面顶部的逻辑模块化了；我们主要看的是executorspage.js这个文件，这里面是获取executor summary数据并渲染的主逻辑。在executorspage.js内部，发现为获取all-executors数据，发送了一个ajax请求</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-4.png" alt=""></p>
<p>这个allexecutors接口有我们想要的executors数据来源信息。全局搜索这个endpoint，发现在AbstractApplicationResource 声明定义了该接口实现</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-5.png" alt=""></p>
<p>意外的发现做了一个类似于请求存储的操作，跟进去发现是AppStatusStore</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-6.png" alt=""></p>
<p>查看类说明，发现这是一个spark 自身kv store的的访问封装实现</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-7.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-8.png" alt=""></p>
<p>追踪到这里，算是对数据来源钻到了尽头，可以知道最终sparkUI上executors summary数据是存在自身实现的kvstore里的</p>
</li>
<li><p>关于kvstore的由来，可以详细看这个<a href="https://issues.apache.org/jira/browse/SPARK-18085" target="_blank" rel="noopener">issule</a> 。大致的点和思路是：Spark History server在查看某一个application运行记录的时候需要从eventlog里面拿出数据渲染；对于少数几个任务来说，目前的实现没有问题，但是如果管理了大量的application，history server就会变的几乎不可用；于是思路是实现一套存储(基于LevelDB或Inmemory结合) 可供history server读写，能大幅提升其页面加载速度</p>
</li>
<li><p>现在我们需要关注一下executorAdded或者removed事件对kvstore里面的数据处理逻辑，看SparkListener中对executor增减接口的定义，追溯到AppStatusListener实现，这也恰好是改变AppStatusStore的入口</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-9.png" alt=""></p>
<p>可见当executor被remove的时候只是将状态置为false，并更新了kvstore里面的值，而不是将其删除，所以前端查询的时候如果发现executor状态不是active且没在blacklist里面的话，默认就把状态format称Dead了</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-10.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-11.png" alt=""></p>
</li>
</ul>
<h4 id="DynamicAllocation-实现机制"><a href="#DynamicAllocation-实现机制" class="headerlink" title="DynamicAllocation 实现机制"></a>DynamicAllocation 实现机制</h4><ul>
<li><p>这里再补充一下DynamicAllocation的底层实现分析。回到之前SparkListener里定义的两个事件处理接口：onExecutorAdded，onExecutorRemoved；其实不止AppStatusListener对这两个事件做了处理，还有ExecutorAllocationListener。这个监听器是触发ExecutorAllocationManager增删executors的入口</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-12.png" alt=""></p>
</li>
<li><p>可以看出里面都是调用的allocationManger里面的具体实现。在onExecutorAdded的callback处理逻辑中，会对新加入的executor做idle记录（onExecutorIdle中实现），先判断当前executor有没有缓存的blocks，走不同的计算timeout分支。其中<strong>cachedExecutorIdleTimeoutS</strong>默认是<strong>Integer.MAX_VALUE</strong> ，然后将记录存入hash结构(<executorid,ideltime>)里，方便<strong>ExecutorAllocationManager</strong>在定时任务下一个周期做检查排除过期的executor</executorid,ideltime></p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-13.png" alt=""></p>
<p>检查逻辑如下：</p>
<p><img src="http://jacobs.wanhb.cn/images/sparkui-14.png" alt=""></p>
</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>从源码分析来看，确实主动和被动释放executor，在sparkUI上面对应的executor状态都会变为Dead。对于使用者来说，如果不清楚spark是否开启了dynamic allocation也确实会引起歧义。毕竟Dead总归是一种不好的状态，甚至逼迫着运维同学去分析一波日志。不知道spark以后的版本中是否会增加一个新的状态？比如引入Released之类的状态将主动和被动区分开，我想这样的话用户体验会更好。</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-01T06:43:09.000Z">2019-05-01</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    22 分钟 读完 (大约 3255 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/01/Raft论文学习/">Raft论文学习</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>分布式系统领域自然离不开一致性协议，而其中以Paxos和Raft最为著称。Paxos和Raft早两年有接触过，受限于当时的知识水平，对实现细节难免囫囵吞枣；最近决心专供分布式系统，于是重新拾起相关Paper开始拜读。以下是Raft 论文读后总结</p>
<h2 id="Raft-五大性质"><a href="#Raft-五大性质" class="headerlink" title="Raft 五大性质"></a>Raft 五大性质</h2><ul>
<li><strong>Election Safety</strong>: 在每一个term里，<em>至多</em>（有可能没有）只能有一个leader被选出</li>
<li><strong>Leader Append-Only</strong>: leader节点不会对自身的log entries 进行覆写/删除的操作；只是单纯的append</li>
<li><strong>Log Matching</strong>: 如果两个log entry 拥有相同的index和term，那么这两个entry是相等</li>
<li><strong>Leader Completeness</strong>: 在一个term中，如果log entry被commit了，那么这个entry 将会存在于所有的其他任期的leader中（<em>也是作为Candidate是否被选中的一个条件</em>）</li>
<li><strong>State Machine Safety</strong>:  如果一个节点apply 了一个log entry，那么带有相同index却不同的log entry是不能被其他任何一个节点所apply</li>
</ul>
<h2 id="Raft-组成部分"><a href="#Raft-组成部分" class="headerlink" title="Raft 组成部分"></a>Raft 组成部分</h2><ul>
<li>Raft 由 Leader，Follower以及Candidate三种角色组成，三者之间组成有限状态机，可在一定事件下互相切换，具体如下图<br><img src="https://pic4.zhimg.com/80/v2-393502082f95a7432687a6fbe19d7cdf_hd.jpg" alt=""></li>
<li>根据上图，角色对应的分工如下<ul>
<li>Follower<ul>
<li>响应candidates和leader的 rpc请求</li>
<li>如果leader在timeout之内未发送心跳，则主动切换为candidate发起新一轮选举</li>
</ul>
</li>
<li>Candidate：主要是选举<ul>
<li>将currentTerm +1，且投给自己，并发起Request Vote RPC给所有其他节点寻求投票</li>
<li>如果收到大多数节点投票，则变成leader，通知所有节点切换为follower</li>
<li>如果通过AppendEntries RPC说明新的leader选举成功，则将自己置为follower</li>
<li><em>可能出现都投自己的情况（极端）</em>：这种情况的处理机制是所有candidate 任意sleep 一段时间（<strong><em>150-300ms</em></strong>），再触发新一轮选举</li>
</ul>
</li>
<li>Leader:<ul>
<li>维持心跳，防止触发leader选举</li>
<li>如果接收到客户端append log请求，leader 会并发地向followers 发起AppendEntries Rpc请求，等大多数follower 节点都返回成功之后再将log entry本地commit,  并将结果最终结果返回给客户端；如果失败则retry，正常的请求处理流程如下图<br><img src="https://pic3.zhimg.com/80/v2-618a3dfc4c9169a6b486416c2c510516_hd.jpg" alt=""></li>
<li>在收到客户端append log 请求后，检测是否最新的log index大于nexIndex 中的值，如果是，则需要给follower 发送AppendEntries RPC请求<ul>
<li>请求成功：更新nextIndex和matchIndex</li>
<li>请求失败：一般是因为leader重选导致<em>数据不一致</em>，则减小nextIndex 重新发送AppendEntries RPC，如此往复，直到找到follower 与 leader 同步的最近一条log entry为止<br><img src="https://pic2.zhimg.com/80/v2-d81511e3cf92859cae0f37d2a05da2e5_hd.jpg" alt=""></li>
</ul>
</li>
<li>如果存在N， N&gt;CommitIndex，大多数matchIndex[follower]&gt;=N，且log[N].term == currentTerm，则将commitIndex 置为N</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="实现Raft的数据结构"><a href="#实现Raft的数据结构" class="headerlink" title="实现Raft的数据结构"></a>实现Raft的数据结构</h2><ul>
<li><p>消息状态划分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Uncommit: 未提交转态（Client发到主节点，主节点还没有得到大多数从节点的提交回执）</span><br><span class="line">Commited: 已提交转态（从节点收到主节点的消息提交，还未收到确认报文）</span><br><span class="line">Applied: 已确认转态（从节点收到主节点的确认报文，或主节点已收到大多数从节点的提交回执）</span><br></pre></td></tr></table></figure>
</li>
<li><p>State ：每个节点的状态</p>
<ul>
<li>在所有节点上都有的</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//实际落盘的</span><br><span class="line">currentTerm：通过rpc接到的最新的任期，初始化为0，随着选举次数增加而增加</span><br><span class="line">votedFor: 保存着一次选举过程中所投的candidateId，为空表示还未投票</span><br><span class="line">log[]: log entries集合，每个entry由记录和所属任期组成 tuple2&lt;command,term&gt;</span><br><span class="line">//在内存中实时可见的</span><br><span class="line">commitIndex: 已确认被commit了的最高位的log entry index</span><br><span class="line">lastApplied: 被当前节点applied的最高位的log entry index</span><br></pre></td></tr></table></figure>
<ul>
<li>在leader 上的状态，每一次选举过后都会在新的leader上重新初始化</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nextIndex[]: 保存着每一个follower节点的下一个log entry index;初始化中leader last log index +1</span><br><span class="line">matchIndex[]: 保存着每一个follower已经被确认replicate成功的最高位的log entry index；初始化为0</span><br></pre></td></tr></table></figure>
<ul>
<li><p>RequestVote RPC 工作模式<br><img src="https://pic1.zhimg.com/80/v2-0b504b0909c97d306c936e4d8a422ee8_hd.jpg" alt=""></p>
</li>
<li><p>AppendEntries RPC工作模式</p>
<ul>
<li>由leader 发起log replicate，以及维护leader to follower 心跳，防止新一轮election触发<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">//rpc 请求参数</span><br><span class="line">term：leader term</span><br><span class="line">leaderId:</span><br><span class="line">pervLogIndex: 上一次apply过的 log 对应的Index</span><br><span class="line">prevLogTerm: 上一次apply过的log 对应的term</span><br><span class="line">entries[]: 要同步的log entries，之所以是数组是优化性能，减少rpc调用次数</span><br><span class="line">leaderCommit: leader最近一次提交的commitIndex</span><br><span class="line">//rpc 返回值</span><br><span class="line">term: follower 当前的term</span><br><span class="line">succss: 如果follower mactch了prevLogIndex和prevLogTerm返回true</span><br><span class="line">//replicate 处理逻辑</span><br><span class="line">如果term&lt; currentTerm，则返回false</span><br><span class="line">如果match 不上prevLogIndex和prevLogTerm 则返回fase</span><br><span class="line">如果当前节点存在相同index但是不同term的entry，则强制删掉该index之后所有的entry，从该节点往后同步leader log entry</span><br><span class="line">如果 leaderCommit &gt; commitIndex, 将commitIndex 设置为min(leaderCommit, index of last new entry)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-01f3b77c9c02f8e2b949b57418f140e1_hd.jpg" alt=""></p>
<h2 id="Leader崩溃"><a href="#Leader崩溃" class="headerlink" title="Leader崩溃"></a>Leader崩溃</h2><h3 id="如何保证follower跟新leader的数据一致性"><a href="#如何保证follower跟新leader的数据一致性" class="headerlink" title="如何保证follower跟新leader的数据一致性"></a>如何保证follower跟新leader的数据一致性</h3><ul>
<li>问题：旧leader挂掉之后，follower通过心跳感知，并转为candidate，触发新一轮选举。新leader产生之后，leader和follower之间很可能存在数据不一致的情况：某些log entry在leader上不存在</li>
<li>Raft的做法是：leader会强制follower 完全复制自己的数据，这样会导致follower上的log entries 可能会被覆写删除（<strong>Kafka中partition leader与follower 之间的Sync参考了这一点</strong>）<br><img src="https://pic4.zhimg.com/80/v2-45bb7e6e89a1d8d5d421d29e3f3a3f5b_hd.jpg" alt=""><ul>
<li>如上图，通过不断的retry之后找到leader和follower之间一致的log entry；从那个entry之后开始同步（强行覆写）<h3 id="如何防止brain-split后log-entries正确性"><a href="#如何防止brain-split后log-entries正确性" class="headerlink" title="如何防止brain split后log entries正确性"></a>如何防止brain split后log entries正确性</h3></li>
</ul>
</li>
<li>问题：如果集群中某一个follower 由于网络问题，长时间没收到leader心跳，如果这时它选自己为leader，等到网络恢复后是不是会成为新的leader覆写之前被commit 的log entry？</li>
<li>Raft做法：增加被选为Leader的限制(<strong>参考性质*Leader Completeness</strong>)<ul>
<li>Raft 确保只有那些包含所有committed log entries（majority） 的candidates 才有资格被选为leader </li>
<li>实现：Vote RPC中包含了candidate 的log 信息，这样voter就可以通过对比自己的日志中log entry 的 index和term来判断candidate 是不是比自己日志更latest<h3 id="如何继续leader-crash之前的commit操作"><a href="#如何继续leader-crash之前的commit操作" class="headerlink" title="如何继续leader crash之前的commit操作"></a>如何继续leader crash之前的commit操作</h3></li>
</ul>
</li>
<li>这个问题存在的前提是新一轮leader election 被选为新leader的节点上保存了上一个leader 未commit成功的log entry；<strong>在raft协议中只确保commit 当前leader中的log entries会按照副本数机制实现(num of replicas &gt; num of node / 2  )</strong><br><img src="https://pic3.zhimg.com/80/v2-51183acb3121e6f1ad07bfc4b49e4ef6_hd.jpg" alt=""><ul>
<li>这种确保的是：如果一条log entry 被当前leader commit成功，那么可以认为之前所有的entries 都commit成功了（<strong>参考特性5 — Log Matching Property</strong> ），<strong>也不需将之前的log entry的term 改成current term</strong></li>
</ul>
</li>
</ul>
<h2 id="Follower-amp-amp-Candidate崩溃"><a href="#Follower-amp-amp-Candidate崩溃" class="headerlink" title="Follower&amp;&amp;Candidate崩溃"></a>Follower&amp;&amp;Candidate崩溃</h2><ul>
<li>follower 和 candidate 崩溃处理方式比较简单<ul>
<li>如果一个follower 或者 candidate 挂掉了，RequestVote 和 AppendEntries RPC 都会失败，处理的方式就是无限次的retry，只要服务重启，就能随着rpc 同步到最新的状态</li>
</ul>
</li>
</ul>
<h2 id="集群扩缩容"><a href="#集群扩缩容" class="headerlink" title="集群扩缩容"></a>集群扩缩容</h2><ul>
<li>目前我们讨论的都是在一组固定的节点上操作，但是在现实中存在因为节点的down掉以及扩容的需求，需要变更集群节点。 如果直接变更的话，可能会出现一段时间brain split的情况。最稳妥的方案就是将服务全部下线，扩容完成之后再重新上线，但是这过于低效<br><img src="https://pic4.zhimg.com/80/v2-fd51d6fa5b917864b632463c272b301b_hd.jpg" alt=""><ul>
<li>如图表示的是滚动升级的情况，逐个重启旧server，会存在新旧两个leader同时存在的情况（各自都赢得了所在集群大多数的vote）</li>
</ul>
</li>
<li>解决方案：<em>引入一种特殊类型的log entry</em>，专门用来做集群配置更替，把它叫做C (old,new)，当C(old,new)被commit之后集群进入 joint consensus（联合一致性），即<em>新旧集群共存</em>的状态。在这种状态下，需遵循的规则如下：<ul>
<li>Log entries将被replicate到新旧配置的所有server节点中</li>
<li>任何一个节点通过新旧任何一份配置都有权利在选举中成为leader</li>
<li>选举结果和log entry commitment的决定需要各自配置中的大多数节点认可</li>
</ul>
</li>
<li>讨论集群扩容的例子<br><img src="https://pic4.zhimg.com/80/v2-01972efd90a47cab1e3e3339a6c4d2e7_hd.jpg" alt=""><ul>
<li>第一阶段：逐台变更时，部分server上处于C(old,new) 状态，此时leader选举只能从C(old, new) 或 C(old) 中产生，具体取决于candidate是否接收到了C(old,new)  log entry；当C(old, new) 被最终committed，则只拥有C(new)和C(old) 的server将再无法被选举为leader（<strong>参考特性4 — Log Matching Property</strong>）</li>
<li>第二阶段：接着再引入一种log entry C(new) ，将它同步到所有节点，等C(new) 最终committed之后则集群切到了C(new)</li>
</ul>
</li>
<li>需注意的点<ul>
<li>新上的节点会存在相对于老集群数据落后的情况，需要一段时间的sync，以追上其他节点，这期间不做任何<em>投票</em>操作（此处可类比Doris 里面Observer的设计理念）</li>
<li>第二阶段结束时，下掉的节点可能不在新集群的配置里面，也就不会接收到心跳，这样可能触发下掉的server leader选举<ul>
<li>为防止扰乱集群可以规定：server如果在timeout允许的范围内正常的接收到了leader的心跳，则会忽略其他RequestVote Rpc请求</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><ul>
<li>日志如果不做压缩处理，理论上会无限期膨胀，期间可能很多重复多余的数据，浪费空间</li>
<li>最简单的做法就是利用snapshot，将系统整个的状态数据作为一个snapshot保存到stable storage上，这样在上一个时间点的snapshot就可以被删除了（FLink的 checkpoint 和Doris的metadata里面也是这么做的）<br><img src="https://pic3.zhimg.com/80/v2-8f6e62d58a0ac891021bc119c3f9f1de_hd.jpg" alt=""></li>
<li>一些其他的方式如：LSM Tree, log cleaning 等都可以</li>
</ul>
<h2 id="客户端设计的原则"><a href="#客户端设计的原则" class="headerlink" title="客户端设计的原则"></a>客户端设计的原则</h2><ul>
<li>首先客户端需要具备请求超时重发机制：请求random server会被reject，如果leader 挂掉触发选举也需要再一次的retry</li>
<li>Raft 对客户端的设计目标是要实现线性一致性语义，这样要求客户端每次command需要分配一个unique serial numer，在server端的state machine中会跟踪client最近一次的serial number，如果被serial number表示的command已经被执行完了则不会被再次执行（<strong>类似Doris 里面mini load Label的概念</strong>）</li>
<li><strong>只读订阅需求</strong>：（<strong>范例可了解Doris 元数据设计</strong>）为了降低leader节点的负载，可以允许client 请求follower节点读取数据；但是有一个缺点就是随着leader选举的过程，可能会读到过期的数据（被commited的数据没有被读到，这不满足线性一致性设计理念），针对这个, 有两种预防措施<ul>
<li>主节点选举成功之后，立即发一个空的log entry到所有节点，这样就触发了集群中所有follower节点向leader强制同步的过程</li>
<li>主节点在响应read-only请求之前必须确认自己是否已经过期，防止自身的信息处于过期的状态；<strong>确认方法是集群中大多数节点发送心跳</strong></li>
</ul>
</li>
</ul>
<h2 id="与Paxos的差异"><a href="#与Paxos的差异" class="headerlink" title="与Paxos的差异"></a>与Paxos的差异</h2><ul>
<li><a href="https://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">Paxos</a> 可以同时提交和处理多个提案，但是发生冲突时，理论上会有更高的延时（协商时间），而Raft算法会天生地把消息确定一个先后顺序。大幅减少了冲突的可能性</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-01-12T04:01:01.000Z">2019-01-12</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 分钟 读完 (大约 822 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/01/12/【spark-tips】spark2-4-0触发的executor内存溢出排查/">【spark-tips】spark2.4.0触发的executor内存溢出排查</a>
            
        </h1>
        <div class="content">
            <h3 id="版本升级背景"><a href="#版本升级背景" class="headerlink" title="版本升级背景"></a>版本升级背景</h3><p>spark 2.4.0 最近刚发版，新增了很多令人振奋的特性。由于本司目前使用的是spark 2.3.0版本，本没打算这么快升级到2.4.0。无奈最近排查出的两个大bug迫使我们只能对spark进行升级。排查的两个bug如下：<br></p>
<ul>
<li><p>spark2.3.0 bug导致driver跑一段时间内存溢出，经过dump下来的堆转储文件发现占绝大内存的对象是spark自身的ElementTrackingStore。这是统计任务运行时资源占用情况的类，在每一个批次处理完之后都没有释放，导致driver内存溢出<br>  <img src="http://jacobs.wanhb.cn/images/memory.png" alt=""></p>
<ul>
<li>详情参考文章：<a href="https://www.cnblogs.com/bethunebtj/p/9103547.html" target="_blank" rel="noopener">导致driver OOM的一个SparkPlanGraphWrapper源码的bug</a></li>
</ul>
</li>
<li>spark streaming 2.3.0 + kafka 0.8.2.1 + zk管理offset 每次重启，会导致offsetrange的左区间莫名向右移动若干offset size，导致每个批次通过offsetrange从kafka消费的数据普遍会丢失部分数据，具体问题还在通过源码定位中</li>
</ul>
<p>第一个bug在spark 2.4.0中得到解决（<a href="https://issues.apache.org/jira/browse/SPARK-23670" target="_blank" rel="noopener">参考issue</a>），于是对spark进行了升级。所幸spark升级对spark on yarn这种运行方式来说非常解耦，只需要定义spark.jars依赖就行，yarn nodemanager会对依赖包进行下载。</p>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>spark 版本升级之后，当天对在线任务观察，运行平稳，上一节提到的bug也修复了；但是第二天离线任务的运行却出现了问题：部分离线任务在做聚合运算的时候出现executor 集体内存溢出，任务执行失败</p>
<h4 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h4><ul>
<li><p>查看日志发现是内存溢出导致executor触发钩子异常退出</p>
<p>  <img src="http://jacobs.wanhb.cn/images/spark_1.png" alt=""></p>
</li>
<li><p>进一步发现在某个计算步骤，需要读入上一个步骤写入hdfs的数据，每个task处理的数据量比较大，且都放到了内存中（<em>导火线</em>）<br>  <img src="http://jacobs.wanhb.cn/images/spark_2.png" alt=""></p>
</li>
<li><p>接着因为要做各种聚合运算（reduceby, groupgy, join…）execution 的内存也不断增大，濒临内存的限制边缘 8G * 0.6(spark.memory.fraction) =4.8G，很容易就会来不及spill到磁盘，导致内存溢出<br>  <img src="http://jacobs.wanhb.cn/images/spark_2.png" alt=""></p>
</li>
<li><p>于是基本可以得到问题原因：从读入hdfs的源头去排查，为什么导致一个task处理的数据量过大；发现hdfs中上一步save到hdfs中的每一个part都是将近500M大小的parquet+snappy 压缩文件，而这种格式无法切分，导致一个map task只能对这400多M的文件照单全收，而由于我应用申请的配置是 <em>8 cores 8 mem / executor</em> 导致8个task同时读入大文件到executor jvm中，最终jvm报内存溢出异常<br>  <img src="http://jacobs.wanhb.cn/images/spark_4.png" alt=""></p>
</li>
</ul>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ul>
<li>限制executor 并行度，将cores 调小，内存适当调大</li>
<li>由于上一步写hdfs的操作并行度太小（只有40），重新调整并行度，让输出的每个part文件减小</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2018-12-20T12:19:06.000Z">2018-12-20</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    25 分钟 读完 (大约 3777 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/12/20/Flink实战总结/">Flink实战总结</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Flink 近几年来一直备受业界瞩目，相对于同时期一夜成名的Spark来说，有种厚积薄发的味道。 当然，从根本上来看，也是因为这几年对于实时分布式计算引擎的需求日渐强烈，要求也越来越高（数据的latency，一致性）。而这也意味着以微批次来fake实时处理的Spark Streaming不再能满足实时处理系统的硬性要求(忽略spark continuous processing实现)。最近本司也正在考虑将实时处理任务从Spark Streaming迁移到Flink；于是就有了下面这篇实战总结文章。</p>
<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><ul>
<li>flink程序能实现在分布式的结合上进行各种转换操作，集合通常来自订阅的来源（文件，kafka,local,in-memory），结果被返回到sinks里（大多数写入分布式文件系统，或者标准输出）</li>
<li>DataSet and DataStream<ul>
<li>DataSet和DataStream在flink中都代表一种数据结构，是不可变且包含重复记录的集合。区别在于DataSet是有限的集合，而DataStream是无界的</li>
</ul>
</li>
<li>flink 配置interlij ideal 在本地运行调试<ul>
<li>只需要将flink依赖的包引入项目中即可启动项目<br><img src="http://jacobs.wanhb.cn/images/flink1.png" alt="HBase 架构图"></li>
</ul>
</li>
<li><strong>讲解Flink怎么序列化objects，怎么分配内存</strong><a href="https://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html" target="_blank" rel="noopener">Apache Flink: Juggling with Bits and Bytes</a></li>
</ul>
<h3 id="DataStream"><a href="#DataStream" class="headerlink" title="DataStream"></a>DataStream</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/datastream_api.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Flink DataStream API Programming Guide</a></li>
<li>datasource（数据源）: <ul>
<li>File-based: readTextFile, readFile…</li>
<li>Socket-based: socketTextStream</li>
<li>Collection-based: fromCollection, fromElements</li>
<li>custom: addSource, FlinkKafkaConsumer08 or other connectors</li>
</ul>
</li>
</ul>
<h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/batch/" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Flink DataSet API Programming Guide</a></li>
</ul>
<h3 id="savepoint"><a href="#savepoint" class="headerlink" title="savepoint"></a>savepoint</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/state/savepoints.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Savepoints</a></li>
<li>Savepoints are created, owned, and deleted by the user.</li>
<li>目前savepoint和checkpoint实现和format方式都相同（除了checkpoint选择了rocksdb作为state backend，这样format会有些微不同）</li>
<li>Operations：<ul>
<li>Triggering Savepoints： FsStateBackend or RocksDBStateBackend:</li>
<li>Trigger a Savepoint</li>
<li>Cancel Job with Savepoint<ul>
<li><code>bin/flink cancel -s [:targetDirectory] :jobId</code></li>
</ul>
</li>
<li>Resuming from Savepoints <ul>
<li><code>$ bin/flink run -s :savepointPath [:runArgs]</code></li>
</ul>
</li>
<li>Disposing Savepoints<ul>
<li><code>$ bin/flink savepoint -d :savepointPath</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/state/checkpoints.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Checkpoints</a></li>
<li>生命周期是由Flink管理，checkpoint的管理，创建以及释放统一通过Flink，而不需要用户干预</li>
<li><strong>Checkpoints are usually dropped（随应用退出被清除）</strong> after the job was terminated by the user (except if explicitly configured as retained Checkpoints)</li>
<li>checkpoint 优化 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/state/large_state_tuning.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Tuning Checkpoints and Large State</a><ul>
<li>state 双写：一份在distributed storage(HDFS)；一份在local</li>
<li>task-local recovery：默认是关闭的状态,可以通过<code>state.backend.local-recovery</code> 打开</li>
</ul>
</li>
</ul>
<h3 id="Barriers"><a href="#Barriers" class="headerlink" title="Barriers"></a>Barriers</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html" target="_blank" rel="noopener">Apache Flink 1.8-SNAPSHOT Documentation: Data Streaming Fault Tolerance</a></li>
</ul>
<h3 id="Window，waterMark，Trigger"><a href="#Window，waterMark，Trigger" class="headerlink" title="Window，waterMark，Trigger"></a>Window，waterMark，Trigger</h3><ul>
<li><a href="https://www.jianshu.com/p/a883262241ef" target="_blank" rel="noopener">Window，waterMark，Trigger介绍- 简书</a></li>
<li>window<ul>
<li>滚动窗口：分配器将每个元素分配到一个指定窗口大小的窗口中，并且不会重叠；TumblingEventTimeWindows.of(Time.seconds(5))</li>
<li>滑动窗口：滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率；因此可能出现窗口重叠，如果滑动参数小于滚动参数的话；SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5))</li>
<li>会话窗口：通过session活动来对元素进行分组，跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况。当他在一个固定的时间周期内不再收到元素，即非活动间隔产生，那么窗口就会关闭；<ul>
<li>一个session窗口通过一个session间隔来配置，这个session间隔定义了非活跃周期的长度。当这个非活跃周期产生，那么当前的session将关闭并且后续的元素将被分配到新的session窗口中去。如：EventTimeSessionWindows.withGap(Time.minutes(10)</li>
</ul>
</li>
</ul>
</li>
<li>触发器(Triggers)<ul>
<li>触发器定义了一个窗口何时被窗口函数处理</li>
<li>EventTimeTrigger</li>
<li>ProcessingTimeTrigger</li>
<li>CountTrigger</li>
<li>PurgingTrigger</li>
</ul>
</li>
<li>驱逐器(Evictors)</li>
</ul>
<h2 id="任务提交与停止姿势"><a href="#任务提交与停止姿势" class="headerlink" title="任务提交与停止姿势"></a>任务提交与停止姿势</h2><ul>
<li><p>任务提交</p>
<ul>
<li><strong>启动命令详解</strong> :<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/yarn_setup.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: YARN Setup</a></li>
<li><p>参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">   Required</span><br><span class="line">     -n,--container &lt;arg&gt;   Number of YARN container to allocate (=Number of Task Managers)</span><br><span class="line">   Optional</span><br><span class="line">     -D &lt;arg&gt;                        Dynamic properties</span><br><span class="line">     -d,--detached                   Start detached</span><br><span class="line">     -jm,--jobManagerMemory &lt;arg&gt;    Memory for JobManager Container with optional unit (default: MB)</span><br><span class="line">     -nm,--name                      Set a custom name for the application on YARN</span><br><span class="line">     -q,--query                      Display available YARN resources (memory, cores)</span><br><span class="line">     -qu,--queue &lt;arg&gt;               Specify YARN queue.</span><br><span class="line">     -s,--slots &lt;arg&gt;                Number of slots per TaskManager</span><br><span class="line">     -tm,--taskManagerMemory &lt;arg&gt;   Memory per TaskManager Container with optional unit (default: MB)</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths for HA mode</span><br></pre></td></tr></table></figure>
</li>
<li><p>提交到yarn-cluster上需要以 ::y:: 或者::yarn::作为前缀；如: <code>ynm=nm</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink run -c com.jacobs.jobs.realtime.wordcount.WindowWordCount target/real-time-jobs-1.0.0-SNAPSHOT.jar</span><br><span class="line"></span><br><span class="line">flink run -m yarn-cluster -ynm TestSinkUserLogStream -yn 4 -yjm 1024m -ytm 4096m -ys 4 -yqu feed.prod -c com.weibo.api.feed.dm.stream.TestFlinkStream /data1/dm-flink/feed-dm-flink-1.0.4-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>停止任务</strong></p>
<ul>
<li><strong>关闭或重启flink程序不能直接kill掉</strong>，这样会导致flink来不及制作checkpoint，而应该调用flink提供的cancel语意</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//重启正确姿势, with savepoint</span><br><span class="line">1. 调用cancel，cancel之前先触发savepoint</span><br><span class="line">bin/flink cancel -s [:targetDirectory] :jobId -yid: yarnAppId</span><br><span class="line">例子: flink cancel -s hdfs://vcp-yz-nameservice1/user/hcp/hcpsys/feed/flink-checkpoints/test-user-logs 97b4e67859af4bfb1b597355f1c846f3 -yid application_1542801635735_2121</span><br><span class="line">2. 从savepoint中恢复flink程序</span><br><span class="line">bin/flink run -s :savepointPath [:runArgs]</span><br><span class="line">例子: flink run -s hdfs://vcp-yz-nameservice1/user/hcp/hcpsys/feed/flink-checkpoints/test-user-logs/savepoint-97b4e6-22dd5890dd0c -m yarn-cluster -ynm TestSinkUserLogStream -yn 4 -yjm 1024m -ytm 4096m -ys 4 -yqu feed.prod -c com.weibo.api.feed.dm.stream.TestFlinkStream /data1/dm-flink/feed-dm-flink-1.0.4-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
<h2 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h2><h3 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h3><ul>
<li>standalone 启动cluster<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/flink-1.6.0/bin;./start-cluster.sh</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="On-Yarn-Cluster"><a href="#On-Yarn-Cluster" class="headerlink" title="On Yarn Cluster"></a>On Yarn Cluster</h3><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/yarn_setup.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: YARN</a></li>
<li><strong>参考文章</strong><a href="https://zhouhai02.com/post/flink-internals/flink1.6-flip6-flink-on-yarn-arch/" target="_blank" rel="noopener">Flink1.6 - flink on yarn分布式部署架构 - 深山含笑</a></li>
<li><p>架构图<br><img src="http://jacobs.wanhb.cn/images/flink2.png" alt="HBase 架构图"></p>
<ul>
<li>JobManager 和 ApplicationMaster  运行在同一个JVM里</li>
</ul>
</li>
<li><p><strong>on yarn 两种模式</strong></p>
<ul>
<li>session模式：允许运行多个作业在同一个Flink集群中，代价是作业之间没有资源隔离（同一个TM中可能跑多个不同作业的task）</li>
<li>per-job模式（生产环境）：per-job模式是指在yarn上为每一个Flink作业都分配一个单独的Flink集群，这样就解决了不同作业之间的资源隔离问题</li>
</ul>
</li>
<li><strong>摘录参考文章</strong>相比旧的Flink-on-YARN架构（Flink 1.5之前），新的yarn架构带来了以下的优势：<ul>
<li>client可以直接在yarn上面启动一个作业，不在像以前需要先启动一个固定大小的Flink集群然后把作业提交到这个Flink集群上</li>
<li>按需申请容器（指被同一个作业的不同算子所使用的容器可以有不同的CPU/Memory配置），没有被使用的容器将会被释放<br><img src="http://jacobs.wanhb.cn/images/flink3.png" alt="HBase 架构图"></li>
</ul>
</li>
<li>slot资源申请/分配流程分析</li>
<li>请求新TaskExecutor的slot分配<br><img src="http://jacobs.wanhb.cn/images/flink4.png" alt="HBase 架构图"></li>
<li>ResourceManager挂掉 ：不会挂掉task,不断尝试重新注册ResourceManager<strong>详细见参考文章</strong></li>
<li>TaskExecutor挂掉</li>
<li>JobMaster挂掉</li>
</ul>
<h2 id="资源分配相关？"><a href="#资源分配相关？" class="headerlink" title="资源分配相关？"></a>资源分配相关？</h2><ul>
<li>在operator中对并行度的设置将决定任务分配到几个task slot里面去</li>
</ul>
<h2 id="Flink程序运行流程分解"><a href="#Flink程序运行流程分解" class="headerlink" title="Flink程序运行流程分解"></a>Flink程序运行流程分解</h2><h3 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h3><ul>
<li><ol>
<li>Obtain an execution environment</li>
</ol>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">getExecutionEnvironment()</span><br><span class="line">createLocalEnvironment()</span><br><span class="line">createRemoteEnvironment(host: String, port: Int, jarFiles: String*)</span><br></pre></td></tr></table></figure>
<ul>
<li><ol>
<li>Load/create the initial data</li>
</ol>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val text: DataStream[String] = env.readTextFile(&quot;file:///path/to/file&quot;)</span><br></pre></td></tr></table></figure>
<ul>
<li><ol>
<li>Specify transformations on this data</li>
</ol>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//create a new DataStream by converting every String in the original collection to an integer</span><br><span class="line">val mapped = input.map &#123; x =&gt; x.toInt &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><ol>
<li>Specify where to put the results of your computations</li>
</ol>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">writeAsText(path: String)</span><br><span class="line">print()</span><br></pre></td></tr></table></figure>
<ul>
<li><ol>
<li>Trigger the program execution</li>
</ol>
</li>
</ul>
<h2 id="Flink-watermark机制"><a href="#Flink-watermark机制" class="headerlink" title="Flink watermark机制"></a>Flink watermark机制</h2><ul>
<li><p><strong>【重要】详细讲解watermark</strong>:  <a href="https://blog.csdn.net/lmalds/article/details/52704170" target="_blank" rel="noopener">Flink流计算编程—watermark（水位线）</a> </p>
<ul>
<li><p>window 触发的两个条件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、watermark时间 &gt;= window_end_time</span><br><span class="line">2、在[window_start_time,window_end_time)中有数据存在</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/20585530" target="_blank" rel="noopener">摘录：深入理解Flink核心技术 </a></p>
<ul>
<li>纵坐标为event_time，横坐标为processingTime，理想情况自然是两者一致，但实际情况肯定不可能<br><img src="http://jacobs.wanhb.cn/images/flink5.png" alt="HBase 架构图"></li>
</ul>
</li>
<li><a href="http://shiyanjun.cn/archives/1785.html" target="_blank" rel="noopener">摘录：使用EventTime与WaterMark进行流数据处理</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> // 这块结合上图理解watermark的值</span><br><span class="line">@Override</span><br><span class="line">    public final Watermark getCurrentWatermark() &#123;</span><br><span class="line">        long potentialWM = currentMaxTimestamp - maxOutOfOrderness; // 当前最大事件时间戳，减去允许最大延迟到达时间</span><br><span class="line">        if (potentialWM &gt;= lastEmittedWatermark) &#123; // 检查上一次emit的WaterMark时间戳，如果比lastEmittedWatermark大则更新其值</span><br><span class="line">            lastEmittedWatermark = potentialWM;</span><br><span class="line">        &#125;</span><br><span class="line">        return new Watermark(lastEmittedWatermark);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Windowing, WaterMark,Trigger 三者依赖关系<ul>
<li>Windowing：就是负责该如何生成Window，比如Fixed Window、Slide Window，当你配置好生成Window的策略时，Window就会根据时间动态生成，最终得到一个一个的Window，包含一个时间范围：[起始时间, 结束时间)，它们是一个一个受限于该时间范围的事件记录的容器，每个Window会收集一堆记录，满足指定条件会触发Window内事件记录集合的计算处理</li>
<li>WaterMark：它其实不太好理解，可以将它定义为一个函数E=f(P)，当前处理系统的处理时间P，根据一定的策略f会映射到一个事件时间E，可见E在坐标系中的表现形式是一条曲线，根据f的不同曲线形状也不同。假设，处理时间12:00:00，我希望映射到事件时间11:59:30，这时对于延迟30秒以内（事件时范围11:59:30~12:00:00）的事件记录到达处理系统，都指派到时间范围包含处理时间12:00:00这个Window中。事件时间超过12:00:00的就会由Trigger去做补偿了。</li>
<li>Trigger：为了满足实际不同的业务需求，对上述事件记录指派给Window未能达到实际效果，而做出的一种补偿，比如事件记录在WaterMark时间戳之后到达事件处理系统，因为已经在对应的Window时间范围之后，我有很多选择：选择丢弃，选择是满足延迟3秒后还是指派给该Window，选择只接受对应的Window时间范围之后的5个事件记录，等等，这都是满足业务需要而制定的触发Window重新计算的策略，所以非常灵活。</li>
</ul>
</li>
</ul>
<h2 id="Sink-Connectors"><a href="#Sink-Connectors" class="headerlink" title="Sink Connectors"></a>Sink Connectors</h2><ul>
<li>Kafka </li>
<li>Elasticsearch</li>
<li>RabbitMQ</li>
<li>Rolling File Sink (HDFS)<ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/filesystem_sink.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: HDFS Connector</a></li>
</ul>
</li>
<li>Streaming File Sink <ul>
<li>partfile 有三种状态：in-progress, pending,finished；part file先被写成in-progress，一旦被关闭写入，会变成pending，当检查点成功之后，pending状态的文件将变成finished; </li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/connectors/streamfile_sink.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Streaming File Sink</a></li>
<li>Using Row-encoded Output Formats <ul>
<li>可以指定RollingPolicy 来滚动生成分区中的文件</li>
</ul>
</li>
<li>Using Bulk-encoded Output Formats<ul>
<li><strong>支持parquet，orc等文件格式</strong>，批量编码文件</li>
<li>通过BulkWriter.Factory定义不同的文件格式   <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/api/java/org/apache/flink/formats/parquet/avro/ParquetAvroWriters.html" target="_blank" rel="noopener">ParquetAvroWriters (flink 1.7-SNAPSHOT API)</a><br>/Users/lichao15/Documents/github/awesome-big-data/README.md        - <strong>源码：</strong> <a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/filesystem/StreamingFileSink.java" target="_blank" rel="noopener">flink/StreamingFileSink.java at master · apache/flink · GitHub</a></li>
<li>使用这种方式只能配合 <code>OnCheckpointRollingPolicy</code>  使用来滚动生成分区文件，通过设置 <code>env.enableCheckpointing(interval)</code>来设置文件滚动间隔</li>
<li><strong>Streaming to parquet in hdfs 出现问题，内存溢出导致job无限崩溃重启，大量part file</strong></li>
<li>如果失败，将从上一个检查点开始重新store，期间回滚in-progress中的文件，以确保不会重复保存上一个检查点之后的数据</li>
<li><strong>part文件过多问题</strong> <a href="https://stackoverflow.com/questions/52638193/streaming-to-parquet-files-not-happy-with-flink-1-6-1" target="_blank" rel="noopener">Streaming to parquet files not happy with flink 1.6.1 - Stack Overflow</a></li>
<li><strong>rolling parquet file 重点邮件</strong> <a href="http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Streaming-to-Parquet-Files-in-HDFS-td23492.html" target="_blank" rel="noopener">Apache Flink User Mailing List archive. - Streaming to Parquet Files in HDFS</a></li>
<li>注意压缩的时候内存溢出的情况，flink陷入无限的重启循环中<br><img src="http://jacobs.wanhb.cn/images/flink6.png" alt="HBase 架构图"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="StreamingFileSink与Kafka-结合"><a href="#StreamingFileSink与Kafka-结合" class="headerlink" title="StreamingFileSink与Kafka 结合"></a>StreamingFileSink与Kafka 结合</h2><h3 id="如何做到exactly-once？"><a href="#如何做到exactly-once？" class="headerlink" title="如何做到exactly once？"></a>如何做到exactly once？</h3><ul>
<li><a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" target="_blank" rel="noopener"> An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</a><ul>
<li>二阶段提交</li>
</ul>
</li>
<li>partfile 有三种状态：in-progress, pending,finished；part file先被写成in-progress，一旦被关闭写入，会变成pending，当检查点成功之后，pending状态的文件将变成finished;</li>
<li>如果失败，将从上一个检查点开始重新store，期间回滚in-progress中的文件，以确保不会重复保存上一个检查点之后的数据<h3 id="flink如何控制kafka-offset提交与checkpoint-amp-amp-savepoint相结合"><a href="#flink如何控制kafka-offset提交与checkpoint-amp-amp-savepoint相结合" class="headerlink" title="flink如何控制kafka offset提交与checkpoint&amp;&amp;savepoint相结合"></a>flink如何控制kafka offset提交与checkpoint&amp;&amp;savepoint相结合</h3></li>
<li><a href="http://m.sohu.com/a/168546400_617676" target="_blank" rel="noopener">FlinkKafkaConsumer使用详解</a></li>
<li>关闭checkpoint(<strong>Checkpointingdisabled</strong>): <ul>
<li>此时， Flink Kafka Consumer依赖于它使用的具体的Kafka client的自动定期提交offset的行为，相应的设置是 Kafka properties中的 enable.auto.commit (或者 auto.commit.enable 对于Kafka 0.8) 以及 auto.commit.interval.ms</li>
</ul>
</li>
<li>开启checkpoint(<strong>Checkpointingenabled</strong>):<ul>
<li>在这种情况下，Flink Kafka Consumer会将offset存到checkpoint中</li>
<li><strong>制作完checkpoint 一并提交offsets</strong> 当checkpoint 处于completed的状态时（<strong>整个job的所有的operator都收到了这个checkpoint的barrier</strong>）。将offset记录起来并提交，从而保证exactly-once</li>
</ul>
</li>
</ul>
<ul>
<li>::exactly once的两个风险点：可结合savepoint来做::<ul>
<li><ol>
<li>异常退出的情况，没法来得及做checkpoint，而checkpoint间隔太长会导致丢失大量数据；可以通过airflow周期性手动触发savepoint恢复；封装hflink脚本<ul>
<li>解决思路是结合savepoint来做，通过<strong>airflow定时的触发savepoint</strong>操作，防止因checkpoint未及时做数据丢失</li>
<li>规定一分钟savepoint一次，这样即使分钟级别的数据丢失也是可以容忍</li>
</ul>
</li>
</ol>
</li>
<li><ol>
<li>第一点利用savepoint来做也有风险：在做savepoint的时候，如果异常退出，parfile未及时关闭导致数据丢失<ul>
<li><strong>暂时可以认为问题较小？</strong></li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="如何控制背压"><a href="#如何控制背压" class="headerlink" title="如何控制背压"></a><strong>如何控制背压</strong></h3><ul>
<li>如何做到挂很久之后重新启动时限制拉取的消息量？（类似spark.streaming.kafka.maxRatePerPartition）<ul>
<li>背压通过task slot 的stackTrace判断</li>
<li>可以在kafka source那层控制一次性消费量，类似于spark</li>
</ul>
</li>
</ul>
<h2 id="Flink-高性能部署"><a href="#Flink-高性能部署" class="headerlink" title="Flink 高性能部署"></a>Flink 高性能部署</h2><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/jobmanager_high_availability.html" target="_blank" rel="noopener">Apache Flink 1.8-SNAPSHOT Documentation: JobManager High Availability (HA)</a></li>
</ul>
<h2 id="metric监控rest-api"><a href="#metric监控rest-api" class="headerlink" title="metric监控rest api"></a>metric监控rest api</h2><ul>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-master/monitoring/rest_api.html" target="_blank" rel="noopener">Apache Flink 1.8-SNAPSHOT Documentation: Monitoring REST API</a></li>
</ul>
<h2 id="Restart-Strategies"><a href="#Restart-Strategies" class="headerlink" title="Restart Strategies"></a>Restart Strategies</h2><ul>
<li><strong>doc</strong> <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/restart_strategies.html" target="_blank" rel="noopener">Apache Flink 1.7 Documentation: Restart Strategies</a></li>
<li>Fixed Delay Restart Strategy</li>
<li>Failure Rate Restart Strategy</li>
<li>No Restart Strategy</li>
<li>Fallback Restart Strategy</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2018-10-14T16:12:35.000Z">2018-10-15</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    1 小时 读完 (大约 6959 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2018/10/15/Spark学习笔记/">Spark实战总结</a>
            
        </h1>
        <div class="content">
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Spark作为一款分布式计算查询引擎，在大数据领域逐渐扮演着越来越重要的作用。传统的MapReduce因计算模型缺陷导致在面对海量数据，复杂的计算场景下计算效率十分低下。于是Spark作为一种互补的即席查询实现方案被各大公司采用。下面是对Spark一些概念和使用的总结</p>
<h2 id="Spark-基础"><a href="#Spark-基础" class="headerlink" title="Spark 基础"></a>Spark 基础</h2><h3 id="Spark-的构成"><a href="#Spark-的构成" class="headerlink" title="Spark 的构成"></a>Spark 的构成</h3><ul>
<li>ClusterManager: 在standalone模式中即为，Master主节点，控制整个集群，监控worker。在yarn模式中为资源管理器</li>
<li>worker :从节点，负责控制计算节点，启动Executro和Driver。在yarn模式中NodeManager,负责计算节点的控制。</li>
<li>Driver：运行Application的main()函数并且创建SparkContext</li>
<li>Executor: 执行器，是为某Application运行在worker node上的一个进程，启动线程池运行任务上，每个Application拥有一组独立的executors</li>
<li>SparkContext: 整个应用程序的上下文，控制整个应用的生命周期</li>
<li>RDD：Spark的基本计算单元，一组RDD形成执行的有向无环图RDD Graph(DAG)</li>
<li>DAG Scheduler: 根据Job构建基于stage的DAG，并且提交stage给TaskScheduler</li>
<li>TaskScheduler: 可以将提交给它的stage 拆分为更多的task并分发给Executor执行</li>
<li>SparkEnv: 线程级别的上下文，存储运行时的重要组件的引用</li>
<li>DStream: 是一个RDD的序列，由若干RDD组成。在一个batchInterval中，会产生一个RDD，产生的数据统一塞入到这个RDD中，采用内存+磁盘的模式，尽可能放到内存中，当数据量太大时会spill到磁盘中</li>
</ul>
<h3 id="Spark-概念释义"><a href="#Spark-概念释义" class="headerlink" title="Spark 概念释义"></a>Spark 概念释义</h3><ul>
<li>Transformation返回值还是一个RDD。它使用了链式调用的设计模式，对一个RDD进行计算后，变换成另外一个RDD，然后这个RDD又可以进行另外一次转换。这个过程是分布式的。 Action返回值不是一个RDD。它要么是一个Scala的普通集合，要么是一个值，要么是空，最终或返回到Driver程序，或把RDD写入到文件系统中。</li>
<li>Action是返回值返回给driver或者存储到文件，是RDD到result的变换，Transformation是RDD到RDD的变换。只有action执行时，rdd才会被计算生成，这是rdd懒惰执行的根本所在。</li>
<li>Driver是我们提交Spark程序的节点，并且所有的reduce类型的操作都会汇总到Driver节点进行整合。节点之间会将map/reduce等操作函数传递一个独立副本到每一个节点，这些变量也会复制到每台机器上，而节点之间的运算是相互独立的，变量的更新并不会传递回Driver程序。</li>
<li>Spark中分布式执行的条件<ul>
<li>只要生成了task，就都是在executor中执行的，在driver中执行不会单独生成task</li>
<li>生成task的操作有: spark.read 读取文件，之后对文件做各种map, filter, reduce操作，都是针对partition而言的</li>
</ul>
</li>
</ul>
<h2 id="spark-工作机制"><a href="#spark-工作机制" class="headerlink" title="spark 工作机制"></a>spark 工作机制</h2><ul>
<li>一个Job被拆分成若干个Stage，每个Stage执行一些计算，产生一些中间结果。它们的目的是最终生成这个Job的计算结果。而每个Stage是一个task set，包含若干个task。Task是Spark中最小的工作单元，在一个executor上完成一个特定的事情。</li>
<li>除非用户指定持久化操作，否则转换过程中产生的中间数据在计算完毕后会被丢弃，即数据是非持久化的。</li>
<li>窄依赖:父RDD中的一个分区最多只会被子RDD中的一个分区使用，父RDD中，一个分区内的数据是不能被分割的，必须整个交付给子RDD中的一个分区。</li>
<li>宽依赖（Shuffle依赖）：父RDD中的分区可能会被多个子RDD分区使用。因为父RDD中一个分区内的数据会被分割，发送给子RDD的所有分区。因此Shuffle依赖也意味着父RDD与子RDD之间存在着Shuffle过程。</li>
</ul>
<h3 id="Spark作业"><a href="#Spark作业" class="headerlink" title="Spark作业"></a>Spark作业</h3><ul>
<li>Application: 用户自定义的Spark程序，用户提交之后，Spark为App分配资源程序转换并执行。</li>
<li>Driver Program: 运行Application的main函数并且创建SparkContext</li>
<li>RDD DAG： 当RDD遇到Action算子，将之前的所有算子形成一个有向无环图（DAG）。再在Spark中转化为Job,提交到集群进行执行，一个App中可以包含多个Job</li>
<li>Job： RDD Graph触发的作业，由spark Action算子触发，在SparkContext中通过runJob方法向spark提交Job</li>
<li>stage： 每个Job会根据RDD的宽依赖关系被切分很多stage ,每个stage包含一组相同的task，这一组task也叫taskset</li>
<li>Task: 一个分区对应一个Task,Task 执行RDD中对应stage中所包含的算子，Taksk 被封装好后放入Executor的线程池中执行。</li>
</ul>
<h2 id="spark调度原理"><a href="#spark调度原理" class="headerlink" title="spark调度原理"></a>spark调度原理</h2><h3 id="作业调度"><a href="#作业调度" class="headerlink" title="作业调度"></a>作业调度</h3><p>系统的设计很重要的一环便是资源调度。设计者将资源进行不同粒度的抽象建模，然后将资源统一放入调度器，通过一定的算法进行调度。</p>
<ul>
<li>spark的多种运行模式：Local模式，standalone模式、YARN模式，Mesos模式。</li>
</ul>
<h3 id="Standalone-VS-Yarn"><a href="#Standalone-VS-Yarn" class="headerlink" title="Standalone VS Yarn"></a>Standalone VS Yarn</h3><ul>
<li><p>角色对比</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">standalone:  		yarn: </span><br><span class="line">client      		client </span><br><span class="line">Master 	  			ApplicationMaster </span><br><span class="line">Worker 	  			ExecutorRunnable </span><br><span class="line">Scheduler   		YarnClusterScheduler </span><br><span class="line">SchedulerBackend 	YarnClusterSchedulerBackend</span><br></pre></td></tr></table></figure>
</li>
<li><p>在yarn中application Master 与Application Driver 运行于同一个JVM进程中</p>
</li>
<li><p>standalone架构图</p>
<p>  <img src="http://jacobs.wanhb.cn/images/standalone.png" alt="standalone"></p>
</li>
<li><p>on yarn架构图</p>
<p>  <img src="http://jacobs.wanhb.cn/images/on%20yarn.png" alt="on yarn"></p>
</li>
</ul>
<h3 id="application调度"><a href="#application调度" class="headerlink" title="application调度"></a>application调度</h3><p>用户提交到spark中的作业集合，通过一定的算法对每个按一定次序分配集群中资源的过程。</p>
<ul>
<li>FIFO模式，用户先提交的作业1优先分配需要的资源，之后提交的作业再分配资源，依次类推。</li>
<li>Mesos: 粗粒度模式和细粒度模式</li>
<li><p>YARN模式：独占模式，可以控制应用分配资源</p>
<ul>
<li><p>yarn-cluster: 适用于生产环境。client将用户程序提交到到spark集群中就与spark集群断开联系了，此时client将不会发挥其他任何作用，仅仅负责提交。在此模式下。AM和driver是同一个东西，但官网上给的是driver运行在AM里，可以理解为AM包括了driver的功能就像Driver运行在AM里一样，此时的AM既能够向AM申请资源并进行分配，又能完成driver划分RDD提交task等工作</p>
</li>
<li><p>yarn-client: y适用于交互、调试，希望立即看到app的输出。Driver运行在客户端上，先有driver再用AM，此时driver负责RDD生成、task生成和分发，向AM申请资源等 ,AM负责向RM申请资源，其他的都由driver来完成</p>
</li>
</ul>
</li>
</ul>
<h3 id="Job调度"><a href="#Job调度" class="headerlink" title="Job调度"></a>Job调度</h3><p>Job调度就是在application内部的一组Job集合，在application分配到的资源量，通过一定的算法，对每个按一定次序分配Application中资源的过程。</p>
<ul>
<li>FIFO模式：先进先出模式</li>
<li>FAIR模式：spark在多个job之间以轮询的方式给任务进行资源分配，所有的任务拥有大致相当的优先级来共享集群的资源。这就意味着当一个长任务正在执行时，短任务仍可以分配到资源，提交并执行，并且获得不错的响应时间。</li>
</ul>
<h3 id="tasks延迟调度"><a href="#tasks延迟调度" class="headerlink" title="tasks延迟调度"></a>tasks延迟调度</h3><ul>
<li><p>数据本地性：尽量的避免数据在网络上的传输，传输任务为主，将任务传输到数据所在的节点</p>
</li>
<li><p>延时调度机制：拥有数据的节点当前正被其他的task占用，如果预测当前节点结束当前任务的时间要比移动数据的时间还要少，那么调度会等待，直到当前节点可用。否则移动数据到资源充足节点，分配任务执行。</p>
</li>
</ul>
<h2 id="spark-transformation和action的算子"><a href="#spark-transformation和action的算子" class="headerlink" title="spark transformation和action的算子"></a>spark transformation和action的算子</h2><h3 id="transformation"><a href="#transformation" class="headerlink" title="transformation"></a>transformation</h3><ul>
<li>map(func) 返回一个新的分布式数据集，由每个原元素经过func函数处理后的新元素组成 </li>
<li>filter(func) 返回一个新的数据集，由经过func函数处理后返回值为true的原元素组成 </li>
<li>flatMap(func) 类似于map，但是每一个输入元素，会被映射为0个或多个输出元素，(因此，func函数的返回值是一个seq，而不是单一元素) </li>
<li>mapPartitions(func) 类似于map，对RDD的每个分区起作用，在类型为T的RDD上运行时，func的函数类型必须是Iterator[T]=&gt;Iterator[U]</li>
<li>mapPartitionsWithIndex(func) 和mapPartitions类似，但func带有一个整数参数表上分区的索引值，在类型为T的RDD上运行时，func的函数参数类型必须是(int,Iterator[T])=&gt;Iterator[U] </li>
<li>sample(withReplacement,fraction,seed) 根据给定的随机种子seed，随机抽样出数量为fraction的数据 </li>
<li>pipe(command,[envVars]) 通过管道的方式对RDD的每个分区使用shell命令进行操作，返回对应的结果 </li>
<li>union(otherDataSet) 返回一个新的数据集，由原数据集合参数联合而成 </li>
<li>intersection(otherDataset) 求两个RDD的交集 </li>
<li>distinct([numtasks]) 返回一个包含源数据集中所有不重复元素的i新数据集 </li>
<li>groupByKey([numtasks]) 在一个由(K,v)对组成的数据集上调用，返回一个(K,Seq[V])对组成的数据集。默认情况下，输出结果的并行度依赖于父RDD的分区数目，如果想要对key进行聚合的话，使用reduceByKey或者combineByKey会有更好的性能 </li>
<li>reduceByKey(func,[numTasks]) 在一个(K,V)对的数据集上使用，返回一个(K,V)对的数据集，key相同的值，都被使用指定的reduce函数聚合到一起，reduce任务的个数是可以通过第二个可选参数来配置的 </li>
<li>sortByKey([ascending],[numTasks]) 在类型为(K,V)的数据集上调用，返回以K为键进行排序的(K,V)对数据集，升序或者降序有boolean型的ascending参数决定 </li>
<li>join(otherDataset,[numTasks]) 在类型为(K,V)和(K,W)类型的数据集上调用，返回一个(K,(V,W))对，每个key中的所有元素都在一起的数据集 </li>
<li>cogroup(otherDataset,[numTasks]) 在类型为(K,V)和(K,W)类型的数据集上调用，返回一个数据集，组成元素为(K,Iterable[V],Iterable[W]) tuples </li>
<li>cartesian(otherDataset) 笛卡尔积，但在数据集T和U上调用时，返回一个(T,U)对的数据集，所有元素交互进行笛卡尔积 </li>
<li>coalesce(numPartitions) 对RDD中的分区减少指定的数目，通常在过滤完一个大的数据集之后进行此操作 </li>
<li>repartition(numpartitions) 将RDD中所有records平均划分到numparitions个partition中</li>
</ul>
<h3 id="action算子操作"><a href="#action算子操作" class="headerlink" title="action算子操作"></a>action算子操作</h3><ul>
<li>reduce(func) 通过函数func聚集数据集中的所有元素，这个函数必须是关联性的，确保可以被正确的并发执行 </li>
<li>collect() 在driver的程序中，以数组的形式，返回数据集的所有元素，这通常会在使用filter或者其它操作后，返回一个足够小的数据子集再使用 </li>
<li>count() 返回数据集的元素个数 </li>
<li>first() 返回数据集的第一个元素(类似于take(1)) </li>
<li>take(n)  返回一个数组，由数据集的前n个元素组成。注意此操作目前并非并行执行的，而是driver程序所在机器 </li>
<li>takeSample(withReplacement,num,seed) 返回一个数组，在数据集中随机采样num个元素组成，可以选择是否用随机数替换不足的部分，seed用于指定的随机数生成器种子 </li>
<li>saveAsTextFile(path) 将数据集的元素，以textfile的形式保存到本地文件系统hdfs或者任何其他hadoop支持的文件系统，spark将会调用每个元素的toString方法，并将它转换为文件中的一行文本 </li>
<li>takeOrderd(n,[ordering]) 排序后的limit(n) </li>
<li>saveAsSequenceFile(path) 将数据集的元素，以sequencefile的格式保存到指定的目录下，本地系统，hdfs或者任何其他hadoop支持的文件系统，RDD的元素必须由key-value对组成。并都实现了hadoop的writable接口或隐式可以转换为writable </li>
<li>saveAsObjectFile(path) 使用java的序列化方法保存到本地文件，可以被sparkContext.objectFile()加载 </li>
<li>countByKey()  对(K,V)类型的RDD有效，返回一个(K,Int)对的map，表示每一个可以对应的元素个数 </li>
<li>foreache(func) 在数据集的每一个元素上，运行函数func,t通常用于更新一个累加器变量，或者和外部存储系统做交互</li>
</ul>
<h2 id="Spark常用存储格式parquet-详解"><a href="#Spark常用存储格式parquet-详解" class="headerlink" title="Spark常用存储格式parquet 详解"></a>Spark常用存储格式parquet 详解</h2><ul>
<li><a href="https://juejin.im/entry/589932fab123db16a3ace2d1" target="_blank" rel="noopener">新型列式存储格式 Parquet 详解 - 后端 - 掘金</a></li>
<li><p>三个组成部分</p>
<ul>
<li>存储格式(storage format)</li>
<li>对象模型转换器(object model converters)</li>
<li>对象模型(object models) ：简单理解为数据在内存中的表示<br><img src="http://jacobs.wanhb.cn/images/parquet.png" alt="parquet"></li>
</ul>
</li>
<li><p>列式存储</p>
<ul>
<li>把某一列数据连续存储，每一行数据离散存储技术</li>
<li>带来的优化<ul>
<li>查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推</li>
<li>由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O</li>
<li>由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效</li>
</ul>
</li>
</ul>
</li>
<li><p>数据模型</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">message AddressBook &#123;</span><br><span class="line">		required string owner;</span><br><span class="line">		repeated string ownerPhoneNumbers;</span><br><span class="line">		repeated group contacts &#123;</span><br><span class="line">  			required string name;</span><br><span class="line">  			optional string phoneNumber;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>根被叫做message，有多个field</li>
<li>每个field包含三个属性:repetition, type, name<ul>
<li>repetition可以是required（出现1次）, optional（出现0次或1次），repeated（出现0次或者多次）。type可以是一个group或者一个primitive类型</li>
</ul>
</li>
<li>parquet数据类型不需要复杂的Map, List, Set等，而是使用repeated fields 和 groups来表示。例如List和Set可以被表示成一个repeated field,Map可以表示成一个包含有Key-value对的repeated group， 而且key是required的</li>
</ul>
</li>
<li><p>两个概念</p>
<ul>
<li>repetition level ：指明该值在路径中哪个repeated field重复<ul>
<li>针对的是repeted field的 。</li>
<li>它能用一个数字告诉我们在路径中的什么重复字段，此值重复了，以此来确定此值的位置</li>
<li>我们用深度0表示一个纪录的开头（虚拟的根节点），深度的计算忽略非重复字段（标签不是repeated的字段都不算在深度里）</li>
</ul>
</li>
<li>definition level：指明该列的路径上多少个可选field被定义了<ul>
<li>如果一个field是定义的，那么它的所有的父节点都是被定义的</li>
<li>从根节点开始遍历，当某一个field的路径上的节点开始是空的时候我们记录下当前的深度作为这个field的Definition Level</li>
<li>如果一个field的definition Level等于这个field的最大definition Level就说明这个field是有数据的</li>
<li><strong>注意</strong>：是指该路径上有定义的repeated field 和 optional field的个数，不包括required field，因为required field是必须有定义的</li>
</ul>
</li>
</ul>
</li>
<li><p>谓词下推：通过将一些过滤条件尽可能的在最底层执行可以减少每一层交互的数据量，从而提升性能</p>
<ul>
<li>例如”select count(1) from A Join B on A.id = B.id where A.a &gt; 10 and B.b &lt; 100″SQL查询中<ul>
<li>在处理Join操作之前需要首先对A和B执行TableScan操作，然后再进行Join，再执行过滤，最后计算聚合函数返回</li>
<li>但是如果把过滤条件A.a &gt; 10和B.b &lt; 100分别移到A表的TableScan和B表的TableScan的时候执行，可以大大降低Join操作的输入数据</li>
</ul>
</li>
<li>无论是行式存储还是列式存储，都可以在将过滤条件在读取一条记录之后执行以判断该记录是否需要返回给调用者，在Parquet做了更进一步的优化<ul>
<li>优化的方法时对每一个Row Group的每一个Column Chunk在存储的时候都计算对应的统计信息，包括该Column Chunk的最大值、最小值和空值个数。</li>
<li>通过这些统计值和该列的过滤条件可以判断该Row Group是否需要扫描。</li>
<li>另外Parquet未来还会增加诸如Bloom Filter和Index等优化数据，更加有效的完成谓词下推</li>
</ul>
</li>
</ul>
</li>
<li><p>映射下推：它意味着在获取表中原始数据时只需要扫描查询中需要的列</p>
<ul>
<li>在Parquet中原生就支持映射下推，执行查询的时候可以通过Configuration传递需要读取的列的信息</li>
<li>这些列必须是Schema的子集，映射每次会扫描一个Row Group的数据，然后一次性得将该Row Group里所有需要的列的Cloumn Chunk都读取到内存中，每次读取一个Row Group的数据能够大大降低随机读的次数，除此之外，Parquet在读取的时候会考虑列是否连续，如果某些需要的列是存储位置是连续的，那么一次读操作就可以把多个列的数据读取到内存</li>
</ul>
</li>
</ul>
<h2 id="Spark-Stremaing-相关"><a href="#Spark-Stremaing-相关" class="headerlink" title="Spark Stremaing 相关"></a>Spark Stremaing 相关</h2><h3 id="BlockRDD"><a href="#BlockRDD" class="headerlink" title="BlockRDD"></a>BlockRDD</h3><ul>
<li>由spark.streaming.blockInterval和duration决定有多少个BlockRdd</li>
<li><p>Receiver模式</p>
<ul>
<li>一个BatchDuration有几个block就会产生几个partition，可参考<a href="http://spark.apache.org/docs/latest/streaming-kafka-0-8-integration.html#approach-1-receiver-based-approach" target="_blank" rel="noopener">receiver bases approach</a></li>
<li>并行度由手动创建的receiver决定<br><img src="http://jacobs.wanhb.cn/images/receiver%E6%A8%A1%E5%BC%8F.png" alt="receiver模式"></li>
</ul>
</li>
<li><p>direct模式</p>
<ul>
<li>blockRDD不再对实际的分区数量起作用，而是会创建和kafka partitions 相同数量的RDD partitions，可参考<a href="http://spark.apache.org/docs/latest/streaming-kafka-0-8-integration.html#approach-2-direct-approach-no-receivers" target="_blank" rel="noopener">direct approach</a></li>
<li>在实际运行的时候通过下发到executor上的task，边拉取数据边处理，这样即使每个task执行失败，对应分区下面的offset也没有提交，也能通过重启task恢复<br>  <img src="http://jacobs.wanhb.cn/images/direct%E6%A8%A1%E5%BC%8F.png" alt="direct模式"></li>
</ul>
</li>
<li><p>消息消费速率限定</p>
<ul>
<li>开启背压模式：spark.streaming.backpressure.enabled=true<ul>
<li>此模式如果消息堆积严重，会一次性拉取kafka中所有堆积的消息进行处理。很可能会导致程序崩溃</li>
</ul>
</li>
<li><p>设置每个partition消费速率, spark.streaming.kafka.maxRatePerPartition</p>
<ul>
<li><p>对应每个batch拉取到的消息为: </p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxRatePerPartition*partitionNum*batch_interval</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Spark-优化相关"><a href="#Spark-优化相关" class="headerlink" title="Spark 优化相关"></a>Spark 优化相关</h2><h3 id="优化建议"><a href="#优化建议" class="headerlink" title="优化建议"></a>优化建议</h3><ul>
<li>stage 的数量跟一个job中是否要进行shuffle有关，像reduceByKey，groupbyKey等等</li>
<li>尽量用broadcast和filter规避join操作</li>
<li><p>因为每次job partition数量过多，导致hive表中过多小文件产生，所以需要重新指定分区，有以下俩种方法：repartition(numPartitions:Int):RDD[T]和coalesce(numPartitions:Int，shuffle:Boolean=false):RDD[T]<br>他们两个都是RDD的分区进行重新划分，repartition只是coalesce接口中shuffle为true的简易实现，（假设RDD有N个分区，需要重新划分成M个分区）</p>
<ul>
<li>N&lt;M。一般情况下N个分区有数据分布不均匀的状况，利用HashPartitioner函数将数据重新分区为M个，这时需要将shuffle设置为true。</li>
<li>如果N&gt;M并且N和M相差不多，(假如N是1000，M是100)那么就可以将N个分区中的若干个分区合并成一个新的分区，最终合并为M个分区，这时可以将shuff设置为false，在shuffl为false的情况下，如果M&gt;N时，coalesce为无效的，不进行shuffle过程，父RDD和子RDD之间是窄依赖关系。</li>
<li><p>如果N&gt;M并且两者相差悬殊，这时如果将shuffle设置为false，父子ＲＤＤ是窄依赖关系，他们同处在一个stage中，就可能造成Spark程序的并行度不够，从而影响性能，如果在M为1的时候，为了使coalesce之前的操作有更好的并行度，可以讲shuffle设置为true。</p>
</li>
<li><p><strong>总之</strong>：如果shuffle为false时，如果传入的参数大于现有的分区数目，RDD的分区数不变，也就是说不经过shuffle，是无法将RDD的分区数变多的。</p>
</li>
</ul>
</li>
</ul>
<h3 id="参数调优"><a href="#参数调优" class="headerlink" title="参数调优"></a>参数调优</h3><ul>
<li><a href="http://tech.meituan.com/spark-tuning-basic.html" target="_blank" rel="noopener">美团Spark参数调优参考文章</a></li>
<li>最重要的是数据序列化和内存调优。对于大多数程序选择Kyro序列化器并持久化序列后的数据能解决常见的性能问题。</li>
<li><p>Executor</p>
<ul>
<li>每个节点可以起一个或多个Executor。每个Executor上的一个核只能同时执行一个task,如果一个Executor被分到了多个task只能排队依次执行</li>
<li>Executor内存主要分三块：<pre><code>- 1、让task执行我们自己编写的代码，默认占总内存的20%。
- 2、让task通过shuffle过程拉取了上一个stage的task输出后，进行聚合等操作时，默认占用总内存20%；
- 3、让RDD持久化使用，默认60%
</code></pre></li>
<li>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。<pre><code>- 一个CPU core同一时间只能执行一个线程。
- 每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。
</code></pre></li>
</ul>
</li>
<li><p>广播大变量</p>
<ul>
<li>当需要用到外部变量时，默认每个task都会存一份，这样会增加GC次数，使用广播变量能确保一个Executor中只有一份</li>
</ul>
</li>
<li><p>使用Kryo优化序列化性能(如果希望RDD序列化存储在内存中，面临GC问题的时候，优先使用序列化缓存技术)</p>
<ul>
<li>spark没有默认使用Kryo作为序列化类库，是因为Kryo要求注册所有需要序列化的自定义类型，这对开发比较麻烦</li>
</ul>
</li>
</ul>
<h2 id="Spark-内存管理"><a href="#Spark-内存管理" class="headerlink" title="Spark 内存管理"></a>Spark 内存管理</h2><ul>
<li><a href="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html" target="_blank" rel="noopener">参考文章：apache spark内存管理详解</a></li>
</ul>
<h3 id="堆内内存和堆外内存"><a href="#堆内内存和堆外内存" class="headerlink" title="堆内内存和堆外内存"></a>堆内内存和堆外内存</h3><ul>
<li>堆内：Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存<ul>
<li>缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存</li>
<li>执行 Shuffle 时占用的内存被规划为执行（Execution）内存<br>- 剩余部分： Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例</li>
<li>注意：在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常</li>
</ul>
</li>
<li>堆外：进一步优化内存的使用以及提高 Shuffle 时排序的效率， 可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据<ul>
<li>堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差</li>
</ul>
</li>
</ul>
<h3 id="存储管理"><a href="#存储管理" class="headerlink" title="存储管理"></a>存储管理</h3><ul>
<li><p>RDD 的持久化机制</p>
<ul>
<li>RDD 的持久化由 Spark 的 Storage 模块 [7] 负责，实现了 RDD 与物理存储的解耦合</li>
<li>Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来</li>
<li>在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。</li>
<li>Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。</li>
<li>Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD</li>
</ul>
</li>
<li><p>RDD 缓存的过程</p>
<ul>
<li>RDD 在缓存到存储内存之后，Partition 被转换成 Block, 其中Record在堆内占有一块连续的空间</li>
<li>将Partition由不连续的存储空间转换为连续存储空间的过程，Spark称之为”展开”（Unroll）</li>
<li>Block 有序列化和非序列化两种存储格式</li>
<li>用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成</li>
</ul>
</li>
<li><p>淘汰规则</p>
<ul>
<li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li>
<li>新旧 Block 不能属于同一个 RDD，避免循环淘汰</li>
<li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li>
<li>遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。</li>
</ul>
</li>
<li><p>Spark中执行内存管理</p>
<ul>
<li>shuffle write:<ul>
<li>若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</li>
<li>若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。</li>
</ul>
</li>
<li>shuffle read:<ul>
<li>在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。</li>
<li>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。</li>
</ul>
</li>
<li>Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制</li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>









    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous is-invisible is-hidden-mobile">
            <a class="is-flex-grow has-text-black-ter" href="/page/0/">上一页</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/page/2/">下一页</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link is-current" href="/">1</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/page/2/">2</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/page/3/">3</a></li>
            
        </ul>
    </nav>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/profile.jpg" alt="CHAO LI">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        CHAO LI
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        Big Data
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Beijing</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            30
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            0
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            39
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">
                关注我</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/ppoffice/hexo-theme-icarus">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            链接
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://github.com/lichaojacobs" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Github</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.zhihu.com/people/chao-li-11" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">知乎</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.zhihu.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://weibo.com/3101672623/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">微博</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">weibo.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            标签云
        </h3>
        <a href="/tags/BigData/" style="font-size: 10px;">BigData</a> <a href="/tags/Crawler/" style="font-size: 10px;">Crawler</a> <a href="/tags/HBase/" style="font-size: 10px;">HBase</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Hbase/" style="font-size: 12.5px;">Hbase</a> <a href="/tags/InnoDB/" style="font-size: 10px;">InnoDB</a> <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/Kylin/" style="font-size: 10px;">Kylin</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/ReentrantLock/" style="font-size: 10px;">ReentrantLock</a> <a href="/tags/Spark/" style="font-size: 17.5px;">Spark</a> <a href="/tags/Spring/" style="font-size: 10px;">Spring</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/aop/" style="font-size: 12.5px;">aop</a> <a href="/tags/data/" style="font-size: 10px;">data</a> <a href="/tags/infrastructure/" style="font-size: 12.5px;">infrastructure</a> <a href="/tags/ioc/" style="font-size: 12.5px;">ioc</a> <a href="/tags/java8/" style="font-size: 10px;">java8</a> <a href="/tags/kylin/" style="font-size: 12.5px;">kylin</a> <a href="/tags/kylin-Java-源码/" style="font-size: 12.5px;">kylin - Java - 源码</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/paper/" style="font-size: 10px;">paper</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/spring/" style="font-size: 15px;">spring</a> <a href="/tags/sqlGenerator/" style="font-size: 10px;">sqlGenerator</a> <a href="/tags/superset/" style="font-size: 10px;">superset</a> <a href="/tags/事务处理/" style="font-size: 10px;">事务处理</a> <a href="/tags/二次开发/" style="font-size: 10px;">二次开发</a> <a href="/tags/函数式编程/" style="font-size: 10px;">函数式编程</a> <a href="/tags/分布式/" style="font-size: 10px;">分布式</a> <a href="/tags/多线程/" style="font-size: 10px;">多线程</a> <a href="/tags/大数据/" style="font-size: 20px;">大数据</a> <a href="/tags/学习/" style="font-size: 17.5px;">学习</a> <a href="/tags/成长/" style="font-size: 17.5px;">成长</a> <a href="/tags/架构/" style="font-size: 17.5px;">架构</a> <a href="/tags/源码/" style="font-size: 15px;">源码</a> <a href="/tags/读书/" style="font-size: 10px;">读书</a>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-01-06T17:42:13.000Z">2020-01-07</time></div>
                    <a href="/2020/01/07/MR任务在Hadoop子系统中状态流转/" class="title has-link-black-ter is-size-6 has-text-weight-normal">MR任务在Hadoop子系统中状态流转</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-04T17:47:46.000Z">2019-11-05</time></div>
                    <a href="/2019/11/05/Yarn-Federation源码串读/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Yarn Federation源码串读</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-04T17:38:28.000Z">2019-11-05</time></div>
                    <a href="/2019/11/05/Hadoop-Rpc源码分析/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop Rpc源码分析</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-10T05:08:55.000Z">2019-06-10</time></div>
                    <a href="/2019/06/10/【Spark源码分析】Job提交执行过程详解/" class="title has-link-black-ter is-size-6 has-text-weight-normal">【Spark源码分析】Job提交执行过程详解</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-02T05:31:16.000Z">2019-06-02</time></div>
                    <a href="/2019/06/02/【Spark源码分析】Broadcast/" class="title has-link-black-ter is-size-6 has-text-weight-normal">【Spark源码分析】Broadcast</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">一月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/06/">
                <span class="level-start">
                    <span class="level-item">六月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/05/">
                <span class="level-start">
                    <span class="level-item">五月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/10/">
                <span class="level-start">
                    <span class="level-item">十月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/08/">
                <span class="level-start">
                    <span class="level-item">八月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/04/">
                <span class="level-start">
                    <span class="level-item">四月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/03/">
                <span class="level-start">
                    <span class="level-item">三月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/10/">
                <span class="level-start">
                    <span class="level-item">十月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/09/">
                <span class="level-start">
                    <span class="level-item">九月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/08/">
                <span class="level-start">
                    <span class="level-item">八月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/07/">
                <span class="level-start">
                    <span class="level-item">七月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/06/">
                <span class="level-start">
                    <span class="level-item">六月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/05/">
                <span class="level-start">
                    <span class="level-item">五月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/03/">
                <span class="level-start">
                    <span class="level-item">三月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/02/">
                <span class="level-start">
                    <span class="level-item">二月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/01/">
                <span class="level-start">
                    <span class="level-item">一月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2016/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2016</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2016/10/">
                <span class="level-start">
                    <span class="level-item">十月 2016</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                标签
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/BigData/">
                        <span class="tag">BigData</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Crawler/">
                        <span class="tag">Crawler</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/HBase/">
                        <span class="tag">HBase</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop/">
                        <span class="tag">Hadoop</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hbase/">
                        <span class="tag">Hbase</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/InnoDB/">
                        <span class="tag">InnoDB</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/JVM/">
                        <span class="tag">JVM</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Java/">
                        <span class="tag">Java</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Kylin/">
                        <span class="tag">Kylin</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/ReentrantLock/">
                        <span class="tag">ReentrantLock</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Spark/">
                        <span class="tag">Spark</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Spring/">
                        <span class="tag">Spring</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Yarn/">
                        <span class="tag">Yarn</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/aop/">
                        <span class="tag">aop</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/data/">
                        <span class="tag">data</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/infrastructure/">
                        <span class="tag">infrastructure</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/ioc/">
                        <span class="tag">ioc</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/java8/">
                        <span class="tag">java8</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/kylin/">
                        <span class="tag">kylin</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/kylin-Java-源码/">
                        <span class="tag">kylin - Java - 源码</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/mysql/">
                        <span class="tag">mysql</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/paper/">
                        <span class="tag">paper</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/python/">
                        <span class="tag">python</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/spark/">
                        <span class="tag">spark</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/spring/">
                        <span class="tag">spring</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/sqlGenerator/">
                        <span class="tag">sqlGenerator</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/superset/">
                        <span class="tag">superset</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/事务处理/">
                        <span class="tag">事务处理</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/二次开发/">
                        <span class="tag">二次开发</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/函数式编程/">
                        <span class="tag">函数式编程</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/分布式/">
                        <span class="tag">分布式</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/多线程/">
                        <span class="tag">多线程</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/大数据/">
                        <span class="tag">大数据</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/学习/">
                        <span class="tag">学习</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/成长/">
                        <span class="tag">成长</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/架构/">
                        <span class="tag">架构</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/源码/">
                        <span class="tag">源码</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/读书/">
                        <span class="tag">读书</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right ">
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-01-06T17:42:13.000Z">2020-01-07</time></div>
                    <a href="/2020/01/07/MR任务在Hadoop子系统中状态流转/" class="title has-link-black-ter is-size-6 has-text-weight-normal">MR任务在Hadoop子系统中状态流转</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-04T17:47:46.000Z">2019-11-05</time></div>
                    <a href="/2019/11/05/Yarn-Federation源码串读/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Yarn Federation源码串读</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-11-04T17:38:28.000Z">2019-11-05</time></div>
                    <a href="/2019/11/05/Hadoop-Rpc源码分析/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop Rpc源码分析</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-10T05:08:55.000Z">2019-06-10</time></div>
                    <a href="/2019/06/10/【Spark源码分析】Job提交执行过程详解/" class="title has-link-black-ter is-size-6 has-text-weight-normal">【Spark源码分析】Job提交执行过程详解</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-02T05:31:16.000Z">2019-06-02</time></div>
                    <a href="/2019/06/02/【Spark源码分析】Broadcast/" class="title has-link-black-ter is-size-6 has-text-weight-normal">【Spark源码分析】Broadcast</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">一月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/11/">
                <span class="level-start">
                    <span class="level-item">十一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/06/">
                <span class="level-start">
                    <span class="level-item">六月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/05/">
                <span class="level-start">
                    <span class="level-item">五月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">一月 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/10/">
                <span class="level-start">
                    <span class="level-item">十月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/08/">
                <span class="level-start">
                    <span class="level-item">八月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/04/">
                <span class="level-start">
                    <span class="level-item">四月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/03/">
                <span class="level-start">
                    <span class="level-item">三月 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/10/">
                <span class="level-start">
                    <span class="level-item">十月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/09/">
                <span class="level-start">
                    <span class="level-item">九月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/08/">
                <span class="level-start">
                    <span class="level-item">八月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/07/">
                <span class="level-start">
                    <span class="level-item">七月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/06/">
                <span class="level-start">
                    <span class="level-item">六月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/05/">
                <span class="level-start">
                    <span class="level-item">五月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/03/">
                <span class="level-start">
                    <span class="level-item">三月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/02/">
                <span class="level-start">
                    <span class="level-item">二月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2017/01/">
                <span class="level-start">
                    <span class="level-item">一月 2017</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2016/12/">
                <span class="level-start">
                    <span class="level-item">十二月 2016</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2016/10/">
                <span class="level-start">
                    <span class="level-item">十月 2016</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                标签
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/BigData/">
                        <span class="tag">BigData</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Crawler/">
                        <span class="tag">Crawler</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/HBase/">
                        <span class="tag">HBase</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop/">
                        <span class="tag">Hadoop</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hbase/">
                        <span class="tag">Hbase</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/InnoDB/">
                        <span class="tag">InnoDB</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/JVM/">
                        <span class="tag">JVM</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Java/">
                        <span class="tag">Java</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Kylin/">
                        <span class="tag">Kylin</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/ReentrantLock/">
                        <span class="tag">ReentrantLock</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Spark/">
                        <span class="tag">Spark</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Spring/">
                        <span class="tag">Spring</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Yarn/">
                        <span class="tag">Yarn</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/aop/">
                        <span class="tag">aop</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/data/">
                        <span class="tag">data</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/infrastructure/">
                        <span class="tag">infrastructure</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/ioc/">
                        <span class="tag">ioc</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/java8/">
                        <span class="tag">java8</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/kylin/">
                        <span class="tag">kylin</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/kylin-Java-源码/">
                        <span class="tag">kylin - Java - 源码</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/mysql/">
                        <span class="tag">mysql</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/paper/">
                        <span class="tag">paper</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/python/">
                        <span class="tag">python</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/spark/">
                        <span class="tag">spark</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/spring/">
                        <span class="tag">spring</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/sqlGenerator/">
                        <span class="tag">sqlGenerator</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/superset/">
                        <span class="tag">superset</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/事务处理/">
                        <span class="tag">事务处理</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/二次开发/">
                        <span class="tag">二次开发</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/函数式编程/">
                        <span class="tag">函数式编程</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/分布式/">
                        <span class="tag">分布式</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/多线程/">
                        <span class="tag">多线程</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/大数据/">
                        <span class="tag">大数据</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/学习/">
                        <span class="tag">学习</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/成长/">
                        <span class="tag">成长</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/架构/">
                        <span class="tag">架构</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/源码/">
                        <span class="tag">源码</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/读书/">
                        <span class="tag">读书</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/hadoop_logo.jpg" alt="CHAO LI&#39;s Blog" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2020 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_uv">
                共<span id="busuanzi_value_site_uv">0</span>个访客
                </span>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="回到顶端" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>