<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>【Spark源码分析】Job提交执行过程详解 | CHAO LI's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【Spark源码分析】Job提交执行过程详解</h1><a id="logo" href="/.">CHAO LI's Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【Spark源码分析】Job提交执行过程详解</h1><div class="post-meta">Jun 10, 2019<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近恰好有点时间梳理一下整个Spark job提交执行流程的相关源码。首先，给一个总的代码流程图（在Executor那块还需补充完整），方便理解整个处理逻辑</p>
<p><img src="https://pic3.zhimg.com/80/v2-6e794771cf2317012b3986ed35979476_hd.jpg" alt=""></p>
<h2 id="Spark-Job-提交处理过程源码解析"><a href="#Spark-Job-提交处理过程源码解析" class="headerlink" title="Spark Job 提交处理过程源码解析"></a>Spark Job 提交处理过程源码解析</h2><h3 id="submitJob解析"><a href="#submitJob解析" class="headerlink" title="submitJob解析"></a>submitJob解析</h3><ul>
<li>macos IntelliJ 中 command+7 查看DagScheduler所有方法，从submitJob方法开始分析，提交了JobSubmitted事件进事件队列，等待处理</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job1.png" alt=""></p>
<ul>
<li>在<strong>DagScheduler</strong>中有<strong>DAGSchedulerEventProcessLoop</strong>类，主要用来集中分发处理事件队列中的事件</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job2.png" alt=""></p>
<ul>
<li>移步DagScheduler.handleJobSubmitted方法，更新UI数据，同时调用submitStage方法；这里finalStage是createResultStage这个方法从最后一个stage生成所有stage的过程</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job3.png" alt=""></p>
<h3 id="submitStage解析"><a href="#submitStage解析" class="headerlink" title="submitStage解析"></a>submitStage解析</h3><p><img src="http://jacobs.wanhb.cn/images/spark-job4.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job5.png" alt=""></p>
<p>可以看到<strong>getOrCreateParentStages</strong>方法中只有shuffle操作时才会创建新的stage</p>
<ul>
<li>再来看SubmitStage方法实现细节，看之前如果对spark运行有了解的话，也大概知道，submitStage里面是提交task的细节</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job6.png" alt=""></p>
<p>这里先判断几个集合：<strong>waitingStages,runningStages,failedStages</strong>中是否已经存在该stage，防止重复提交stage；通过<strong>getMissingParentStages</strong>，深度遍历地从后往前判断当前stage是否存在需要重新计算的stage，加入<strong>missing stages</strong>集合中。那么什么条件下才算是一个missing stage呢？我们来分析<strong>getMissingParentStages</strong>实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job7.png" alt=""></p>
<p>可以发现判断当前rdd是否被cache了是通过DagScheduler.getCacheLocs获取缓存的location，观察到cacheLocs的数据结构是一个HashMap，key为rdd id，value为TaskLocation集合；虽说HashMap是个非线程安全集合，不过这里写操作线程安全通过加锁实现，所以说用HashMap实现倒也无妨</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job8.png" alt=""></p>
<p>这个集合是在getCacheLocs中写入的</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job9.png" alt=""></p>
<p>如果当前rdd本身没有设置storage level的话，也就无需查找缓存了，直接返回，否则通过blockManagerMaster.getLocations查找具体block对应的位置；blockManagerMaster上存储了所有Executor汇报上来的所有block位置元数据信息<strong>（后面有一小节来分析block的写入和上报过程）</strong></p>
<p>接着，对于rdd如果没有显式缓存的情况，需要遍历rdd所有的依赖，对于是宽依赖的stage，调用<strong>getOrCreateShuffleMapStage</strong>获取或者创建mapStage，通过isAvailable判断所有output是否都已经准备好，isAvailable是通过查询<strong>mapOutputTracker</strong>已经注册的task output信息得到的，对于isAvailable为false的情况，说明output没有，或丢失。需要重新计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Number of partitions that have shuffle outputs.</span><br><span class="line">   * When this reaches [[numPartitions]], this map stage is ready.</span><br><span class="line">   */</span><br><span class="line">  def numAvailableOutputs: Int = mapOutputTrackerMaster.getNumAvailableOutputs(shuffleDep.shuffleId)</span><br><span class="line">  /**</span><br><span class="line">   * Returns true if the map stage is ready, i.e. all partitions have shuffle outputs.</span><br><span class="line">   */</span><br><span class="line">def isAvailable: Boolean = numAvailableOutputs == numPartitions</span><br></pre></td></tr></table></figure>
<h3 id="submitMissingTasks解析"><a href="#submitMissingTasks解析" class="headerlink" title="submitMissingTasks解析"></a><strong>submitMissingTasks解析</strong></h3><ul>
<li>接下来分析submitStage中submitMissingTasks实现，这个方法是根据需要计算的stage来提交stage中的taskset。taskIdToLocation获取task要处理的数据的所在节点</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job10.png" alt=""></p>
<p>然后根据task所属的stage类型来创建实际的task实例(ShuffleMapTask与ResultTask)</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job11.png" alt=""></p>
<p>最后如果待计算的tasks集合不为空，则通过taskScheduler引用将task set提交到TaskScheduler中去调度</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job12.png" alt=""></p>
<p>具体看<strong>TaskSchedulerImpl.submitTasks</strong>实现，首先会创建一个<strong>TaskSetManager</strong>。<strong>TaskSetManager</strong>实际调度TaskSet的的实现，跟踪并且根据数据优先级分发task，以及重试失败的task。因为一个stage同一时刻只能有至多一个<strong>TaskSetManager</strong>处于活跃状态，所以创建完<strong>TaskSetManager</strong>实例之后，需要将Stage中其他<strong>TaskSetManager</strong>实例标记为<strong>Zombie</strong>状态</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job13.png" alt=""></p>
<p>随后，根据运行模式来判断要不要启动资源分配情况是否是饥饿状态的监控线程，最后调用<strong>CoarseGrainedSchedulerBackend.reviveOffers()</strong> 方法开始task调度</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job14.png" alt=""></p>
<p>实际上是发了一个actor消息，直接看receive中针对ReviveOffers消息的处理方法(<strong>CoarseGrainedSchedulerBackend.makeOffers</strong>)实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job15.png" alt=""></p>
<h3 id="Scheduler-resourceOffers解析"><a href="#Scheduler-resourceOffers解析" class="headerlink" title="Scheduler.resourceOffers解析"></a>Scheduler.resourceOffers解析</h3><ul>
<li>先筛选出存活的executor，然后调用TaskSchedulerImpl.resourceOffers方法开始为每个TaskSet中的task分配具体执行节点</li>
<li>在分配前将那些之前被加入黑名单又重新生效的节点包括进来；然后打散workerOffer集合，防止task分配不均</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job16.png" alt=""></p>
<ul>
<li>获取shuffleOffer中节点剩余cpu以及slot(cores/CPU_PER_TASK(default 1))集合availableCpus，availableSlots</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</span><br><span class="line">val availableSlots = shuffledOffers.map(o =&gt; o.cores / CPUS_PER_TASK).sum</span><br></pre></td></tr></table></figure>
<ul>
<li><p>获取sortedTaskSets，在循环期间随时关注是否有新的executor加入</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job17.png" alt=""></p>
</li>
<li><p>对sortedTaskSets集合的每个taskSet，如果taskSet是barrier模式，且可用slot小于taskSet中的task数量，则直接跳过分配；因为barrier模式中，所有的task都需要并行启动</p>
</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job18.png" alt=""></p>
<ul>
<li>对于非barrier模式的taskSet，根据taskSet中所有tasks的数据优先级调度task。如下图，myLocalityLevels是taskSet中所有tasks数据本地性优先级集合。由TaskSetManager. computeValidLocalityLevels方法计算得到</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job19.png" alt=""></p>
<ul>
<li>优先级从高到低依次为<strong>PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</strong> 也是按照这个顺序优先调度task</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job20.png" alt=""></p>
<ul>
<li><p>具体的调度见<strong>TaskSchedulerImpl.resourceOfferSingleTaskSet</strong>方法，里面实际依赖<strong>TaskSetManager.resourceOffer</strong>方法</p>
</li>
<li><ul>
<li>首先对应的executor不能是被拉入黑名单，且当前TaskSetManager不能被标记为zombie</li>
<li>从taskSet中出队一个指定locality的 task（实现见TaskSetManager.dequeueTask）加入runningTasks结合中。对于非barrier模式的stage来说，只要有task被调度成功了就可以跑起来</li>
</ul>
</li>
<li><p>这里再回过头看CoarseGrainedSchedulerBackend.makeOffers实现。当调用scheduler.resourceOffers之后如果有TaskDescription集合返回的的话，就可以调用launchTasks了</p>
</li>
<li><ul>
<li>在launchTasks方法中，发送了LaunchTask消息，将序列化的Task信息通过rpc发送给Executor端（CoarseGrainedExecutorBackend实现）</li>
<li><img src="http://jacobs.wanhb.cn/images/spark-job22.png" alt=""></li>
</ul>
</li>
<li><p>看CoarseGrainedExecutorBackend.receive中对LaunchTask消息的处理逻辑</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job23.png" alt=""></p>
</li>
<li><p>executor.launchTask中，实例化了TaskRunner，并将taskRunner提交到线程池中调度执行。<strong>具体的执行逻辑在下一个小节描述</strong></p>
</li>
</ul>
<h2 id="ShuffleMapTask-block写入过程分析"><a href="#ShuffleMapTask-block写入过程分析" class="headerlink" title="ShuffleMapTask block写入过程分析"></a><strong>ShuffleMapTask block写入过程分析</strong></h2><ul>
<li>在上文中，我们分析到了TaskRunner。直接跳到TaskRunner里面的run方法实现</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job25.png" alt=""></p>
<p>可以看到通过执行执行task.run方法拿到执行task后的结果，跟进去看结果是什么数据结构。</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job26.png" alt=""></p>
<p>发现调用了runTask方法，查看接口的定义，发现有多个实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job27.png" alt=""></p>
<p>看到了熟悉的<strong>ShuffleMapTask</strong>,<strong>ResultTask</strong>字眼，结果明朗了，其实就是根据宽窄依赖来调用具体的Task实现。<strong>ResultTask</strong>生成的result是func在rdd各个partition上的执行结果而<strong>ShuffleMapTask</strong>生成的result是shuffle 文件输出信息(<strong>MapStatus</strong>)</p>
<ul>
<li>我们选<strong>ShuffleMapTask.runTask</strong>实现分析，返回的数据结构是<strong>MapStatus，MapStatus</strong>封装了task 所在的blockManager的信息（executorId+host+port）以及map task到每个reducer task的输出FileSegment的大小</li>
</ul>
<p><img src="http://jacobs.wanhb.cn/images/spark-job28.png" alt=""></p>
<p>来分析outputFile的实现细节，首先这里需要获取具体的ShuffleWriter实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job29.png" alt=""></p>
<p>每个shuffleId对应的ShuffleHandle（也即是ShuffleWriter实现）由ShuffleManager统一管理，通过registerShuffle注册具体的ShuffleWriter</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job30.png" alt=""></p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job31.png" alt=""></p>
<p>如图所示，目前spark中的shuffleWriter实现大概有三种，这里不详细比较，后续有专门文章分析Spark ShuffleWriter实现；选最常用的<strong>SortShuffleWriter.write</strong> 实现深入分析MapStatus产生过程</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job32.png" alt=""></p>
<p>可以看到SortShuffleWriter对于每个mapTask只会产生一个output，通过indexfile start和end offset 来计算后续reduceTask获取数据的位置，这样做大大减小了output 文件数量。最终返回mapStatus结果</p>
<ul>
<li><p><a href="https://link.zhihu.com/?target=http%3A//%E4%BA%8E%E6%98%AF%E7%8E%B0%E5%9C%A8%E7%9F%A5%E9%81%93%E8%B0%83%E7%94%A8TaskRunner.run" target="_blank" rel="noopener">于是现在知道调用TaskRunner.run</a> 根据task的类型不同返回的结果也是不同的，统一将其包装成DirectResult发送到driver上；这里根据实际得到的resultSize有不同的处理情况</p>
</li>
<li><ul>
<li>如果result比较大，超过了maxDirectResultSize则会先把result存到本地的blockManager托管，storageLevel是内存+磁盘，然后把存储信息封装成IndirectTaskResult发送给driver</li>
<li>否则直接将序列化的result发送给driver。通过statusUpdate封装StatusUpdate事件将result发送给driver端处理</li>
<li><img src="http://jacobs.wanhb.cn/images/spark-job33.png" alt=""></li>
</ul>
</li>
<li><p>这里可以再分析一下result过大，blockManager是如何处理的细节。先看<strong>blockManager.doPutBytes</strong>，这里可以看到优先将result写入本地内存(LinkedHashMap实现)，如果内存不够<strong>（totalSize&gt;memory*spark.storage.memoryFraction）</strong>，则会将result通过diskStore直接写入磁盘</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job34.png" alt=""></p>
</li>
<li><p>看CoarseGrainedSchedulerBackend中具体处理StatusUpdate的实现，这里其实嵌套的比较多。按正常的路径首先会经过<strong>taskResultGetter.enqueueSuccessfulTask</strong>方法，在这里会将result反序列化（有<strong>DirectTaskResult</strong>与<strong>IndirectTaskResult</strong>之分），接着调用<strong>DagScheduler.handleSuccessfulTask</strong>。这里按照task类型不同有不同的处理方式：</p>
<ul>
<li><p>task是ResultTask的话，可以使用ResultHandler对result进行driver端计算（比如count()会对所有ResultTask的result做sum）</p>
</li>
<li><p>如果是ShuffleMapTask的话会注册mapOutputTracker，方便后续reduce task查询，然后submit 下一个stage</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job35.png" alt=""></p>
</li>
</ul>
</li>
</ul>
<h2 id="Rdd-Cache的过程"><a href="#Rdd-Cache的过程" class="headerlink" title="Rdd Cache的过程"></a>Rdd Cache的过程</h2><ul>
<li><p>分析至此，我们似乎还没看到ShuffleMapTask cache的过程，只知道如果是ResultTask产生的数据会优先塞入内存（不够溢写磁盘）。那么我们在平时操作中调用的rdd.cache在哪个环节起作用了呢？其实我们分析ShuffleMapTask处理过程时，忽略了一块代码（ShuffleMapTask.runTask 中 rdd.iterator的调用）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ShuffleMapTask.runTask</span><br><span class="line">=&gt; writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &lt;: Product2[Any, Any]]])</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入iterator实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Rdd.iterator</span><br><span class="line">=&gt; getOrCompute (if storageLevel != StorageLevel.NONE)</span><br><span class="line">=&gt; computeOrReadCheckPoint (if storageLevel == StorageLevel.NONE)</span><br></pre></td></tr></table></figure>
</li>
<li><p>发现这里获取rdd的时候取决于当前rdd的存储方式，默认应该是<strong>StorageLevel.NONE</strong>，显示调cache的话将会走<strong>getOrCompute</strong>读取缓存逻辑，先看rdd不缓存的情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RDD.computeOrReadCheckpoint</span><br><span class="line">=&gt; 如果被checkpoint了，读checkpoint数据</span><br><span class="line">=&gt; 如果没有则直接重新计算</span><br></pre></td></tr></table></figure>
<p>如果有checkpoint会获取，否则直接compute重新计算rdd。看<strong>getOrCompute</strong>实现</p>
<p><img src="http://jacobs.wanhb.cn/images/spark-job38.png" alt=""></p>
<ul>
<li>核心还是调用从blockManager中去拿缓存的rdd或者重新计算更新blockManager，在getLocalValues方法里面会根据当前的StorageLevel到memory或者diskStore里面去拿blockResult，发现diskStore.getBytes实现里面，<strong>diskManager.getFile</strong>方法正是SortShuffleWriter中获取output路径的底层实现</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DiskStore.getBytes</span><br><span class="line">=&gt; val file = diskManager.getFile(blockId.name)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SortShuffleWriter.write</span><br><span class="line">=&gt; val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)</span><br><span class="line">IndexShuffleBlockResolver.getDataFile</span><br><span class="line">	 =&gt;blockManager.diskBlockManager.getFile(ShuffleDataBlockId(shuffleId, mapId, NOOP_REDUCE_ID))		 </span><br><span class="line">     =&gt;DiskManager.getFile</span><br></pre></td></tr></table></figure>
</li>
<li><p>经过一番分析，也能看出，cache主要适用于数据量不大的且反复使用的rdd；如果数据量过大，会发生频繁的数据溢写，还可能导致OOM的错误，收益大于成本，需要慎用</p>
</li>
<li>至此，shuffleMapTask从提交到输出到磁盘，以及DagScheduler如何处理Task Completion事件分析完了。后续文章中将分析ResultTask如何从<strong>mapOutputTracker</strong>拉取数据，以及如何计算的逻辑</li>
</ul>
</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=http://ol7zjjc80.bkt.clouddn.com/271524552778_.pic.jpg&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden;overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2019/06/10/【Spark源码分析】Job提交执行过程详解/" data-id="ck61tnbz4001d7uyhth4l5mbv" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACrUlEQVR42u3aQXKDMAwF0Nz/0u1MtynwJdnA4rHKhCT4uTOWKunzia+fv+vone/XR3e/P/N9N/nNxRceHh5ea+lHV/Vh599K1pBv2fma8fDw8HbzekdzQu0trhpsDt/Hw8PDe5SXb8F8a/KwgYeHh/dmXnKIVxPlaoDBw8PDew8vAeTFhbymmrO311rw8PDwYl61AfaG1xv7e3h4eHiDrnp+4K4KJ5Om1z9rwMPDw9vASwaqeg2tXukh35rCxuHh4eEt5fUY1eR7Hgyaw154eHh4G3jJKToZC6gmx5PRgahWjYeHhzfmJY/pjU9VG1qrist4eHh4d/KqDac8SOQjXPkoVbQ1eHh4eA/x8qJtfjdP2atJ/z+1Fjw8PLxtvF6bf9VwQJ6mF9aMh4eHt42XFEbzz+fp9TyEXGwTHh4e3jbepKHVO9znYSMq7+Lh4eFt4yWL7oWE3sBBtfzR7I/h4eHhDXjJF6qFiWrAKLS18vQdDw8P7yFeNQxMRg0mhd3oPwY8PDy8RbyLBvyi4sKOs/pizXh4eHgbeJPWVK/ckCfWeUG5EKLw8PDwxrw8qU0O3/lOV0cKLv5ieHh4eBt4vbZTtVw7GcOqbj0eHh7ebt58IKD34JsSdzw8PLyHeEnaOi/4TtaDh4eH9xQvf/88hMzT7mpSXhgdwMPDwxvzqqlzcpT3mmF5Wbk63ICHh4e3lter++aAfEGfwXX4FDw8PLxbeHnxNB+QOt+IVcXiw4iHh4eHt5RXPXx7r1fl/tXQhYeHh7ePVw0G1YZWdZhgMhyGh4eHdycvL9HmIST/tfJYQD7igIeHh/cor7e4agst2dDC1uPh4eG9hpcPQvXCQLWUHE1G4OHh4S3l9R5WHSCoNq56zTY8PDy83bxqA6xXtO0d/aOBADw8PLz1vF9u74i9Qk+kMgAAAABJRU5ErkJggg==" class="article-share-link">分享</a><div class="tags"><a href="/tags/大数据/">大数据</a><a href="/tags/学习/">学习</a><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a href="/2019/11/05/Hadoop-Rpc源码分析/" class="pre">Hadoop Rpc源码分析</a><a href="/2019/06/02/【Spark源码分析】Broadcast/" class="next">【Spark源码分析】Broadcast</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8yOTg3MC82NDM1"><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/Hbase/" style="font-size: 15px;">Hbase</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/kylin/" style="font-size: 15px;">kylin</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/infrastructure/" style="font-size: 15px;">infrastructure</a> <a href="/tags/data/" style="font-size: 15px;">data</a> <a href="/tags/多线程/" style="font-size: 15px;">多线程</a> <a href="/tags/ReentrantLock/" style="font-size: 15px;">ReentrantLock</a> <a href="/tags/spring/" style="font-size: 15px;">spring</a> <a href="/tags/ioc/" style="font-size: 15px;">ioc</a> <a href="/tags/aop/" style="font-size: 15px;">aop</a> <a href="/tags/源码/" style="font-size: 15px;">源码</a> <a href="/tags/事务处理/" style="font-size: 15px;">事务处理</a> <a href="/tags/InnoDB/" style="font-size: 15px;">InnoDB</a> <a href="/tags/BigData/" style="font-size: 15px;">BigData</a> <a href="/tags/成长/" style="font-size: 15px;">成长</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/分布式/" style="font-size: 15px;">分布式</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/Kylin/" style="font-size: 15px;">Kylin</a> <a href="/tags/kylin-Java-源码/" style="font-size: 15px;">kylin - Java - 源码</a> <a href="/tags/superset/" style="font-size: 15px;">superset</a> <a href="/tags/二次开发/" style="font-size: 15px;">二次开发</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Crawler/" style="font-size: 15px;">Crawler</a> <a href="/tags/学习/" style="font-size: 15px;">学习</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/java8/" style="font-size: 15px;">java8</a> <a href="/tags/sqlGenerator/" style="font-size: 15px;">sqlGenerator</a> <a href="/tags/函数式编程/" style="font-size: 15px;">函数式编程</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/01/07/MR任务在Hadoop子系统中状态流转/">MR任务在Hadoop子系统中状态流转</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/Yarn-Federation源码串读/">Yarn Federation源码串读</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/05/Hadoop-Rpc源码分析/">Hadoop Rpc源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/10/【Spark源码分析】Job提交执行过程详解/">【Spark源码分析】Job提交执行过程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/02/【Spark源码分析】Broadcast/">【Spark源码分析】Broadcast</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/26/【Spark源码分析】Dynamic-Resource-Allocation设计的思考/">【Spark源码分析】Dynamic Resource Allocation设计的思考</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/01/Raft论文学习/">Raft论文学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/【spark-tips】spark2-4-0触发的executor内存溢出排查/">【spark-tips】spark2.4.0触发的executor内存溢出排查</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/Flink实战总结/">Flink实战总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/Spark学习笔记/">Spark实战总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/chao-li-11/activities" title="知乎" target="_blank">知乎</a><ul></ul><a href="http://weibo.com/3101672623/profile?topnav=1&amp;wvr=6" title="微博" target="_blank">微博</a><ul></ul><a href="https://github.com/lichaojacobs" title="GitHub" target="_blank">GitHub</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">CHAO LI's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?4ca08f1c48fe3bf3d0e2bfb54473d985## Your Baidu Analytics tracking id, e.g. 8006843039519956000";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>