<!DOCTYPE html>
<html class="full-height">
<head>
  <meta charset="utf-8">
  <link rel="stylesheet" href="//cdn.bootcss.com/bulma/0.4.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  
  <title>python 爬取新浪微博 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="最近因为课设的要求，开始了对新浪微博数据的爬取研究，看了不少博客文章，也试了不少方法，原理无非就是模拟登录，但是感觉目前可用的方法太过分散，而且自从微博改版之后，很多以前适用的方法都基本没有用处了。这里总结一下几种可用的方法以及自己研究之后稳定可用的方法(所有的方法都是基于python2.7)：

###1、绕过.com域名
如果没有爬取主站的刚需，只是对微博相关的数据感兴趣，可以尝试爬取微博cn">
<meta property="og:type" content="article">
<meta property="og:title" content="python 爬取新浪微博">
<meta property="og:url" content="http://yoursite.com/2016/12/01/python-爬取新浪微博/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="最近因为课设的要求，开始了对新浪微博数据的爬取研究，看了不少博客文章，也试了不少方法，原理无非就是模拟登录，但是感觉目前可用的方法太过分散，而且自从微博改版之后，很多以前适用的方法都基本没有用处了。这里总结一下几种可用的方法以及自己研究之后稳定可用的方法(所有的方法都是基于python2.7)：

###1、绕过.com域名
如果没有爬取主站的刚需，只是对微博相关的数据感兴趣，可以尝试爬取微博cn">
<meta property="og:updated_time" content="2016-11-30T17:25:15.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python 爬取新浪微博">
<meta name="twitter:description" content="最近因为课设的要求，开始了对新浪微博数据的爬取研究，看了不少博客文章，也试了不少方法，原理无非就是模拟登录，但是感觉目前可用的方法太过分散，而且自从微博改版之后，很多以前适用的方法都基本没有用处了。这里总结一下几种可用的方法以及自己研究之后稳定可用的方法(所有的方法都是基于python2.7)：

###1、绕过.com域名
如果没有爬取主站的刚需，只是对微博相关的数据感兴趣，可以尝试爬取微博cn">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/common.css">
<link rel="stylesheet" href="/css/nav.css">
<link rel="stylesheet" href="/css/layout.css">
  

</head>

<body>
  <header id="navbar" class="overflow-hidden">
  <div class="container">
    <nav class="nav">
         <div class="nav-left">
            <a href="/" class="nav-item" style="font-size: 20px;">
              <span class="logo">CHAO LI</span>'s Blog
            </a>
         </div>
        <div class="nav-center is-hidden position-relative" id="search_container">
            <div class="nav-item full-width full-height">
                <i class="fa fa-search has-padding" aria-hidden="true"></i>
                <input type="text" id="search_input" class="search-input full-height full-width" placeholder="Search post" autofocus>
                <i id="close_search" class="fa fa-times" aria-hidden="true"></i>
            </div>
            <div id="search_result"></div>
        </div>
        <div class="nav-right nav-menu">
            <a class="nav-item" id="search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
            
            <a class="nav-item" href="/">
                Home
            </a>
            
            <a class="nav-item" href="/works">
                My Works
            </a>
            
            <a class="nav-item" href="/about">
                About
            </a>
            
        </div>
        <span class="nav-toggle" id="navMenuDropdown">
            <span></span>
            <span></span>
            <span></span>
        </span>
        <div class="navbar-menu position-absolute full-width content-box is-hidden-desktop is-flex flex-column center" style="top: 100%;">
            
            <a class="nav-item flex-1" href="/">
                Home
            </a>
            
            <a class="nav-item flex-1" href="/works">
                My Works
            </a>
            
            <a class="nav-item flex-1" href="/about">
                About
            </a>
            
        </div>
    </nav>
  </div>
</header>

  <div id="main-wrap" class="position-relative" style="margin-top: 55px;">
      <div class="main-inner-content">
          <!--博文页面-->

<style>
    .header-box {
        height: 370px;
        filter: blur(10px);
        background-size: cover;
        background-color: lightsteelblue;
    }

    .post-box {
        padding: 15px;
        padding-top: 60px;
        min-height: 80vh;
        margin-top: -200px;
        border-radius: 4px;
        background-color: rgba(255,255,255,.8);
    }

    .post-avatar {
        height: 30px;
        width: 30px;
        border-radius: 50%;
    }

    .flow-chart {
        text-align: center;
    }

    img[alt="post-cover"] {
        display: none;
    }
</style>
<header>
    <div id="header_box" class="header-box"></div>
</header>
<section>
    <div class="container post-box">
        <div class="content post-title is-flex center flex-column" style="margin-bottom: 70px; overflow: auto;">
            <h1 class="has-text-centered" style="padding-bottom: 10px; border-bottom: 3px solid #fff">
                <strong>python 爬取新浪微博</strong>
            </h1>
            
            <div class="is-flex align-center">
                <img class="post-avatar" src="https://cdn2.iconfinder.com/data/icons/rcons-user/32/male-shadow-circle-512.png">
                <span style="padding:0 10px;"> <span class="sub-title">By</span> CHAO LI</span>
                <span class="post-date sub-title">at: 2016-12-01</span>
            </div>
            
                <div>
                    
                         <a class="tag is-post-tag" href="/tags/Python/">Python</a>
                    
                         <a class="tag is-post-tag" href="/tags/Crawler/">Crawler</a>
                    
                </div>
            
        </div>
        <div class="content" style="overflow: auto">
            <p>最近因为课设的要求，开始了对新浪微博数据的爬取研究，看了不少博客文章，也试了不少方法，原理无非就是模拟登录，但是感觉目前可用的方法太过分散，而且自从微博改版之后，很多以前适用的方法都基本没有用处了。这里总结一下几种可用的方法以及自己研究之后稳定可用的方法(所有的方法都是基于python2.7)：</p>
<hr>
<p>###1、绕过.com域名</p>
<p>如果没有爬取主站的刚需，只是对微博相关的数据感兴趣，可以尝试爬取微博cn域名下的内容(即<a href="http://weibo.cn)，亲测可用...最简单的办法就是先预先登录一下然后获取返回的cookie，贴入代码中作为请求的headers即可。" target="_blank" rel="external">http://weibo.cn)，亲测可用...最简单的办法就是先预先登录一下然后获取返回的cookie，贴入代码中作为请求的headers即可。</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">_header=&#123;</div><div class="line">        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.86 Safari/537.36&quot;,</div><div class="line">        &quot;Cookie&quot;:&quot;_T_WM=03e77f532a8c1a437da863b36a62207d; SUB=_2A256KfecDeRxGeVP61MX9yzKyT-IHXVZ1ZnUrDV6PUNbvtANLRTVkW1LHesQJOUc8nbbLnoALvjmulMBSwDnAw..; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WhPUuFTXg4zll8rx_8Ap-XA5JpX5KMhUgL.Foepeh2cS0zceoet; SUHB=0cSXC9tcKk2RM7; SSOLoginState=1462601676; gsid_CTandWM=4uTtCpOz5hhWcws1tVSIdd0SYa3&quot;    &#125;</div><div class="line"> request = urllib2.Request(url=url, headers=self._header)</div><div class="line"> response = urllib2.urlopen(request)</div><div class="line"> html = response.read()</div></pre></td></tr></table></figure>
<p>接下来对爬取下来的html就可以通过xpath,或者bs来完成数据提取了。</p>
<hr>
<p>###2、使用urllib模拟登录微博.com主站</p>
<p>这个过程比较麻烦，前人有了很多铺垫做相应的改动直接拿来用就好啦，以下代码亲测可用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div></pre></td><td class="code"><pre><div class="line">-*- coding: utf-8 -*-import urllib2</div><div class="line">import re</div><div class="line">import rsa</div><div class="line">import cookielib  #从前的cookielibimport base64</div><div class="line">import json</div><div class="line">import urllib</div><div class="line">import binascii</div><div class="line">from lxml import etree</div><div class="line">import json</div><div class="line"> 用于模拟登陆新浪微博class launcher():</div><div class="line"> </div><div class="line">    cookieContainer=None    _headers=&#123;</div><div class="line">            &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36&quot;        &#125;</div><div class="line">    def __init__(self,username, password):</div><div class="line">        self.password = password</div><div class="line">        self.username = username</div><div class="line"></div><div class="line"></div><div class="line">    def get_prelogin_args(self):</div><div class="line">        json_pattern = re.compile(&apos;\((.*)\)&apos;)</div><div class="line">        url = &apos;http://login.sina.com.cn/sso/prelogin.php?entry=weibo&amp;callback=sinaSSOController.preloginCallBack&amp;su=&amp;&apos; + self.get_encrypted_name() + &apos;&amp;rsakt=mod&amp;checkpin=1&amp;client=ssologin.js(v1.4.18)&apos;        try:</div><div class="line">            request = urllib2.Request(url)</div><div class="line">            response = urllib2.urlopen(request)</div><div class="line">            raw_data = response.read().decode(&apos;utf-8&apos;)</div><div class="line">            print &quot;get_prelogin_args&quot;+raw_data;</div><div class="line">            json_data = json_pattern.search(raw_data).group(1)</div><div class="line">            data = json.loads(json_data)</div><div class="line">            return data</div><div class="line">        except urllib2.HTTPError as e:</div><div class="line">            print(&quot;%d&quot;%e.code)</div><div class="line">            return None    def get_encrypted_pw(self,data):</div><div class="line">        rsa_e = 65537 #0x10001        pw_string = str(data[&apos;servertime&apos;]) + &apos;\t&apos; + str(data[&apos;nonce&apos;]) + &apos;\n&apos; + str(self.password)</div><div class="line">        key = rsa.PublicKey(int(data[&apos;pubkey&apos;],16),rsa_e)</div><div class="line">        pw_encypted = rsa.encrypt(pw_string.encode(&apos;utf-8&apos;), key)</div><div class="line">        self.password = &apos;&apos;   #清空password        passwd = binascii.b2a_hex(pw_encypted)</div><div class="line">        print(passwd)</div><div class="line">        return passwd</div><div class="line"></div><div class="line"></div><div class="line">    def get_encrypted_name(self):</div><div class="line">        username_urllike   = urllib.quote(self.username)</div><div class="line">        byteStr=bytes(username_urllike)</div><div class="line">        byteStrEncod=byteStr.encode(encoding=&quot;utf-8&quot;)</div><div class="line">        username_encrypted = base64.b64encode(byteStrEncod)</div><div class="line">        return username_encrypted.decode(&apos;utf-8&apos;)</div><div class="line"></div><div class="line"></div><div class="line">    def enableCookies(self):</div><div class="line">            #建立一个cookies 容器            self.cookieContainer = cookielib.MozillaCookieJar(&quot;/Users/lichao/desktop/weibo/cookie/cookie.txt&quot;);</div><div class="line">            # ckjar=cookielib.MozillaCookieJar(&quot;/Users/Apple/Desktop/cookie.txt&quot;)            #将一个cookies容器和一个HTTP的cookie的处理器绑定            cookie_support = urllib2.HTTPCookieProcessor(self.cookieContainer)</div><div class="line">            #创建一个opener,设置一个handler用于处理http的url打开            opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)</div><div class="line">            #安装opener，此后调用urlopen()时会使用安装过的opener对象            # proxy_handler = urllib2.ProxyHandler(&#123;&quot;http&quot;: &apos;http://localhost:5000&apos;&#125;)            # opener=urllib2.build_opener(proxy_handler)            urllib2.install_opener(opener)</div><div class="line"></div><div class="line"></div><div class="line">    def build_post_data(self,raw):</div><div class="line">        post_data = &#123;</div><div class="line">            &quot;entry&quot;:&quot;weibo&quot;,</div><div class="line">            &quot;gateway&quot;:&quot;1&quot;,</div><div class="line">            &quot;from&quot;:&quot;&quot;,</div><div class="line">            &quot;savestate&quot;:&quot;7&quot;,</div><div class="line">            &quot;useticket&quot;:&quot;1&quot;,</div><div class="line">            &quot;pagerefer&quot;:&quot;Sina Visitor System&quot;,</div><div class="line">            &quot;vsnf&quot;:&quot;1&quot;,</div><div class="line">            &quot;su&quot;:self.get_encrypted_name(),</div><div class="line">            &quot;service&quot;:&quot;miniblog&quot;,</div><div class="line">            &quot;servertime&quot;:raw[&apos;servertime&apos;],</div><div class="line">            &quot;nonce&quot;:raw[&apos;nonce&apos;],</div><div class="line">            &quot;pwencode&quot;:&quot;rsa2&quot;,</div><div class="line">            &quot;rsakv&quot;:raw[&apos;rsakv&apos;],</div><div class="line">            &quot;sp&quot;:self.get_encrypted_pw(raw),</div><div class="line">            &quot;sr&quot;:&quot;1280*800&quot;,</div><div class="line">            &quot;encoding&quot;:&quot;UTF-8&quot;,</div><div class="line">            &quot;prelt&quot;:&quot;77&quot;,</div><div class="line">            &quot;url&quot;:&quot;http://weibo.com/ajaxlogin.php?framelogin=1&amp;callback=parent.sinaSSOController.feedBackUrlCallBack&quot;,</div><div class="line">            &quot;returntype&quot;:&quot;META&quot;        &#125;</div><div class="line">        data = urllib.urlencode(post_data).encode(&apos;utf-8&apos;)</div><div class="line">        return data</div><div class="line"></div><div class="line"></div><div class="line">    def login(self):</div><div class="line">        url = &apos;新浪通行证&apos;        self.enableCookies()</div><div class="line">        data = self.get_prelogin_args()</div><div class="line">        post_data = self.build_post_data(data)</div><div class="line">        headers = &#123;</div><div class="line">            &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.87 Safari/537.36&quot;        &#125;</div><div class="line">        try:</div><div class="line">            request = urllib2.Request(url=url,data=post_data,headers=headers)</div><div class="line">            response = urllib2.urlopen(request)</div><div class="line">            html = response.read().decode(&apos;GBK&apos;)</div><div class="line">            #print(html)        except urllib2.HTTPError as e:</div><div class="line">            print(e.code)</div><div class="line"></div><div class="line"></div><div class="line">        p = re.compile(&apos;location\.replace\(\&apos;(.*?)\&apos;\)&apos;)</div><div class="line">        p2 = re.compile(r&apos;&quot;userdomain&quot;:&quot;(.*?)&quot;&apos;)</div><div class="line"></div><div class="line"></div><div class="line">        try:</div><div class="line">            login_url = p.search(html).group(1)</div><div class="line">            print(login_url)</div><div class="line">            request = urllib2.Request(login_url)</div><div class="line">            response = urllib2.urlopen(request)</div><div class="line">            page = response.read().decode(&apos;utf-8&apos;)</div><div class="line">            print(page)</div><div class="line">            login_url = &apos;http://weibo.com/&apos; + p2.search(page).group(1)</div><div class="line">            request = urllib2.Request(login_url)</div><div class="line">            response = urllib2.urlopen(request)</div><div class="line">            final = response.read().decode(&apos;utf-8&apos;)</div><div class="line"></div><div class="line"></div><div class="line">            print(&quot;Login success!&quot;)</div><div class="line">            self.cookieContainer.save(ignore_discard=True, ignore_expires=True)</div><div class="line">        except Exception, e:</div><div class="line">            print(&apos;Login error!&apos;)</div><div class="line">            print e</div><div class="line">            return 0</div></pre></td></tr></table></figure>
<p>###3、使用selenium实现模拟登录</p>
<ul>
<li>selenium +phantomjs</li>
</ul>
<p>第二种方法有一个问题，因为目前新版的微博页面的渲染方式采用的是分片渲染的，这就导致我们通过第二种静态方式爬取到的页面并不是最终的页面，而是内容嵌在 js里的中间页面，这肯定不是我们想看到的结果。于是，考虑模拟浏览器渲染页面的方式获取到最终的呈现页面。selenium这个工具正好完美的解决了我们的问题，它可以模拟浏览器的行为，并且我们拿到的source可以向jquery操作dom对象那样查找定位元素，非常方便，实现的核心代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import time</div><div class="line">from selenium import webdriver</div><div class="line">import urllib2</div><div class="line">import selenium.webdriver.support.ui as ui</div><div class="line">import sys</div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding( &quot;utf-8&quot; )</div><div class="line">from selenium.webdriver.common.keys import Keys</div><div class="line">Chrome PhantomJS#driver = webdriver.PhantomJS(&quot;/Users/test/documents/phantomjs/bin/phantomjs&quot;)</div><div class="line">driver.get(&apos;http://weibo.com/&apos;)</div><div class="line"></div><div class="line"></div><div class="line">try:</div><div class="line">    print &quot;登录开始&quot;</div><div class="line">    username = driver.find_element_by_xpath(&apos;//input[@name=&quot;username&quot;]&apos;)</div><div class="line">    password = driver.find_element_by_xpath(&apos;//input[@name=&quot;password&quot;]&apos;)</div><div class="line">    sbtn = driver.find_element_by_xpath(&apos;//a[@action-type=&quot;btn_submit&quot;]&apos;)</div><div class="line">    username.send_keys(&apos;&apos;) #send username       </div><div class="line">    password.send_keys(&apos;&apos;) #send password    sbtn.click()  </div><div class="line">    # 提交表单    </div><div class="line">    time.sleep(3)  # 等待页面加载   </div><div class="line">    # get the session cookie    </div><div class="line">    cookie = &#123;item[&quot;name&quot;] + &quot;:&quot; + item[&quot;value&quot;] for item in driver.get_cookies()&#125;    cookie=driver.get_cookies()</div><div class="line">    for item in driver.get_cookies():    cookieItem=&#123;&quot;name&quot;:item[&quot;name&quot;],&quot;value&quot;:item[&quot;value&quot;],&quot;domain&quot;:item[&quot;domain&quot;],&quot;httponly&quot;:item[&quot;httponly&quot;],&quot;path&quot;:item[&quot;path&quot;],&quot;secure&quot;:item[&quot;secure&quot;]&#125;    cookie.append(cookieItem)    cookie_file= open(&quot;/Users/test/desktop/weibo/cookie/cookie.txt&quot;,&apos;w&apos;)    cookie_file.write(str(cookie))    print str(str(cookie))</div><div class="line">except urllib2.HTTPError as e:</div><div class="line">    print e</div><div class="line">    print &quot;登录失败&quot;print &quot;开始爬取谣言大厅&quot;driver.get(&quot;http://service.account.weibo.com/show?rid=K1CaN7gJl8q8f&quot;)</div><div class="line">page = driver.page_source</div><div class="line">print page</div><div class="line">driver.quit()</div></pre></td></tr></table></figure>
<p>我们将登录之后获取的cookie以键值对的形式存入文本文件中，方便下次直接load而不需要重复登录:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def loadCookie(self):</div><div class="line">self._driver.get(&quot;http://www.sina.com.cn&quot;)</div><div class="line">    cookie_file=open(&quot;/Users/test/desktop/weibo/cookie/cookie.txt&quot;,&apos;r&apos;)</div><div class="line">    cookieStr=cookie_file.read();</div><div class="line">print &quot;cookie is: &quot;+cookieStr</div><div class="line">    cookieList=list(eval(cookieStr))</div><div class="line">for item in cookieList:</div><div class="line">cookieDic= type(eval(item))</div><div class="line">        self._driver.add_cookie(item)</div></pre></td></tr></table></figure>
<ul>
<li>selenium +chromedirver</li>
</ul>
<p>使用phantomjs存在一个问题，登录过程老是失败，因为验证码无法识别获取导致登录经常失败，这里我们使用chromedirver这工具结合selenium实现开挂级别的python数据爬取，模拟登录万无一失，核心代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">print &quot;登录开始&quot;</div><div class="line">username = driver.find_element_by_xpath(&apos;//input[@name=&quot;username&quot;]&apos;)</div><div class="line">password = driver.find_element_by_xpath(&apos;//input[@name=&quot;password&quot;]&apos;)</div><div class="line">sbtn = driver.find_element_by_xpath(&apos;//a[@action-type=&quot;btn_submit&quot;]&apos;)</div><div class="line">veryfiCode=driver.find_element_by_xpath(&apos;//input[@name=&quot;verifycode&quot;]&apos;)</div></pre></td></tr></table></figure>
<p> 程序启动时会自动开启一个chrome窗口，只不过这个浏览器的行为我们可以通过程序控制，这样是不是方便多了！我们在username这一行打一个断点，然后程序执行到这一步，在浏览器中输入相应的用户名，密码，验证码，然后在pycharm中点击继续，登录成功！真实浏览器结合程序，真是开挂级别的爬取微博啊…</p>

        </div>
        <div class="post-reply">
            
            
            <div id="disqus_thread" style="width: 80%; margin: 0 auto;"></div>
                <script>

                    /**
                     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
                     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
                    /*
                     var disqus_config = function () {
                     this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
                     this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
                     };
                     */
                    (function() { // DON'T EDIT BELOW THIS LINE
                        var d = document, s = d.createElement('script');
                        s.src = 'https://jacobs-wanhb.disqus.com/embed.js';
                        s.setAttribute('data-timestamp', +new Date());
                        (d.head || d.body).appendChild(s);
                    })();
                </script>
                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            
        </div>
    </div>
</section>
<script>
    // 获取第一张图, 用以当封面背景图
    var img = document.querySelectorAll('img')[1]

    if (img) {
        var header_box = document.querySelector('#header_box')
        header_box.style.backgroundImage = 'url('+ img.src +')'
    }
</script>
      </div>
  </div>
  <style>
  #footer {
    min-height: 10vh;
    background: black;
    color: #fff;
  }

  #footer a {
    color: #e1e1e1;
  }
</style>
<footer id="footer" class="has-text-centered is-flex center">
  <div class="container has-padding">
    <div>
      <div>
        <!--请您保留作者署名, 主题制作来之不易-->
        Theme by <a href="http://haojen.github.io/">Haojen Ma</a>
        <br>
        Copyright © John Doe 2017
        <br>
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      </div>
    </div>
  </div>
</footer>

<script src="/js/search_core.js"></script>
<script src="/js/script.js"></script>

</body>
</html>